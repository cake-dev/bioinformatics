{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "# generate a random DNA sequence of length 10000bp\n",
    "def generate_random_sequence(length):\n",
    "    dna = \"\"\n",
    "    for i in range(length):\n",
    "        dna += random.choice(\"ACGT\")\n",
    "    return dna\n",
    "\n",
    "# generate a random DNA sequence of length 10000bp\n",
    "dna = generate_random_sequence(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import List, Dict, Iterable\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# ------------------------ Generate Reads ------------------------ #\n",
    "def generate_reads(dna: str, read_len: int, coverage: float) -> List[str]:\n",
    "    \"\"\"Generates reads from a DNA string with specified read length and coverage.\"\"\"\n",
    "    genome_len = len(dna)\n",
    "    num_reads = int(genome_len * coverage / read_len)\n",
    "    reads = []\n",
    "    for _ in range(num_reads):\n",
    "        start_pos = random.randint(0, genome_len - read_len)\n",
    "        reads.append(dna[start_pos:start_pos + read_len])\n",
    "    return reads\n",
    "\n",
    "# ------------------------ Break Reads into k-mers ------------------------ #\n",
    "def break_reads_into_kmers(reads: List[str], k: int, g: int) -> List[str]:\n",
    "    \"\"\"Breaks a list of reads into k-mers with a gap of g.\"\"\"\n",
    "    kmers = []\n",
    "    for read in reads:\n",
    "        for i in range(0, len(read) - k + 1, g + 1):  # Step by g+1\n",
    "            kmers.append(read[i:i+k])\n",
    "    return kmers\n",
    "\n",
    "# ------------------------ De Bruijn Graph from k-mers ------------------------ #\n",
    "def de_bruijn_kmers(k_mers: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"Forms the de Bruijn graph of a collection of k-mers.\"\"\"\n",
    "    adj_list = defaultdict(list)\n",
    "    for k_mer in k_mers:\n",
    "        prefix = k_mer[:-1]\n",
    "        suffix = k_mer[1:]\n",
    "        adj_list[prefix].append(suffix)\n",
    "    return dict(adj_list)\n",
    "\n",
    "# ------------------------ Eulerian Path ------------------------ #\n",
    "def extend_cycle(cycle: List[str], marked_graph: Dict[str, List[str]]) -> List[str]:\n",
    "    \"\"\"Extends the Eulerian cycle from a given node in the marked graph.\"\"\"\n",
    "    if cycle:\n",
    "        cycle.pop()  # remove the repeated node at the end\n",
    "        new_start_index = next(i for i, node in enumerate(cycle) if node in marked_graph)\n",
    "        cycle = cycle[new_start_index:] + cycle[:new_start_index]\n",
    "        cycle.append(cycle[0])  # re-add the repeated node\n",
    "        current_node = cycle[-1]\n",
    "    else:\n",
    "        current_node = next(iter(marked_graph))  # get an arbitrary node from the graph\n",
    "        cycle = [current_node]\n",
    "    \n",
    "    while current_node in marked_graph:\n",
    "        old_node = current_node\n",
    "        current_node = marked_graph[old_node].pop()\n",
    "        if not marked_graph[old_node]:\n",
    "            del marked_graph[old_node]  # remove the node if no more edges\n",
    "        cycle.append(current_node)\n",
    "    \n",
    "    return cycle\n",
    "\n",
    "def eulerian_cycle_str(g: Dict[str, List[str]]) -> List[str]:\n",
    "    \"\"\"Constructs an Eulerian cycle in a graph. Assumes the graph is Eulerian and connected.\"\"\"\n",
    "    cycle = []\n",
    "    while g:\n",
    "        cycle = extend_cycle(cycle, g)\n",
    "    return cycle\n",
    "\n",
    "def fix_unbalanced(g: Dict[str, List[str]]) -> tuple[str, str]:\n",
    "    \"\"\"Finds and fixes unbalanced nodes in the graph.\"\"\"\n",
    "    total_degree = defaultdict(int)\n",
    "    \n",
    "    for node1, adj_nodes in g.items():\n",
    "        for node2 in adj_nodes:\n",
    "            total_degree[node1] += 1  # Out-degree\n",
    "            total_degree[node2] -= 1  # In-degree\n",
    "\n",
    "    s, t = None, None\n",
    "    for node, tot_degree in total_degree.items():\n",
    "        if tot_degree == 1:\n",
    "            t = node\n",
    "        elif tot_degree== -1:\n",
    "            s = node\n",
    "\n",
    "    if s and t:\n",
    "        g.setdefault(s, []).append(t)\n",
    "    \n",
    "    return s, t\n",
    "\n",
    "def eulerian_path(g: Dict[str, List[str]]) -> List[str]:\n",
    "    \"\"\"Constructs an Eulerian path in a graph, assuming the graph is nearly Eulerian.\"\"\"\n",
    "    s, t = fix_unbalanced(g)\n",
    "    cycle = eulerian_cycle_str(g)\n",
    "    \n",
    "    if s:\n",
    "        cycle.pop()  # Remove the duplicate last node\n",
    "        t_index = next(i for i, (u, v) in enumerate(zip(cycle, cycle[1:])) if u == s and v == t)\n",
    "        cycle = cycle[t_index + 1:] + cycle[:t_index + 1]\n",
    "    \n",
    "    return cycle\n",
    "\n",
    "# ------------------------ String Spelled by a Genome Path ------------------------ #\n",
    "def genome_path(path: List[str]) -> str:\n",
    "    \"\"\"Forms the genome path formed by a collection of patterns.\"\"\"\n",
    "    if not path:\n",
    "        return \"\"\n",
    "    result = path[0]\n",
    "    for i in range(1, len(path)):\n",
    "        result += path[i][-1]\n",
    "    return result\n",
    "\n",
    "# ------------------------ Assemble Sequence ------------------------ #\n",
    "def assemble_sequence(dna: str, read_len: int, coverage: float, k: int, g: int) -> str:\n",
    "    \"\"\"Assembles a DNA sequence from reads using a De Bruijn graph.\"\"\"\n",
    "    reads = generate_reads(dna, read_len, coverage)\n",
    "    kmers = break_reads_into_kmers(reads, k, g)  # Pass g here\n",
    "    graph = de_bruijn_kmers(kmers)\n",
    "    path = eulerian_path(graph)\n",
    "    assembled_sequence = genome_path(path)\n",
    "    return assembled_sequence\n",
    "\n",
    "# # ------------------------ Main Execution ------------------------ #\n",
    "# if __name__ == \"__main__\":\n",
    "#     dna_string = input(\"Enter DNA string: \")\n",
    "#     read_length = int(input(\"Enter read length: \"))\n",
    "#     coverage_percentage = float(input(\"Enter coverage percentage (e.g., 0.5 for 50%): \"))\n",
    "#     kmer_length = int(input(\"Enter k-mer length: \"))\n",
    "\n",
    "#     assembled_dna = assemble_sequence(dna_string, read_length, coverage_percentage, kmer_length)\n",
    "#     print(\"Assembled DNA sequence:\", assembled_dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_string = generate_random_sequence(1000)\n",
    "read_length = 20\n",
    "coverage_percentage = 1.0\n",
    "kmer_length = 10\n",
    "gap = 1\n",
    "\n",
    "assembled_dna = assemble_sequence(dna_string, read_length, coverage_percentage, kmer_length, gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tS\tI0\tM1\tD1\tI1\tM2\tD2\tI2\tE\n",
      "S\t0\t0\t1.000\t0\t0\t0\t0\t0\t0\n",
      "I0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "M1\t0\t0\t0\t0\t0.625\t0.375\t0\t0\t0\n",
      "D1\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I1\t0\t0\t0\t0\t0\t0\t0.800\t0.200\t0\n",
      "M2\t0\t0\t0\t0\t0\t0\t1.000\t0\t0\n",
      "D2\t0\t0\t0\t0\t0\t0\t0\t0\t1.000\n",
      "I2\t0\t0\t0\t0\t0\t0\t0\t0\t1.000\n",
      "E\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "\n",
      "--------\n",
      "\tA\tB\tC\tD\tE\n",
      "S\t0\t0\t0\t0\t0\n",
      "I0\t0\t0\t0\t0\t0\n",
      "M1\t0\t0\t0\t0\t1.000\n",
      "D1\t0\t0\t0\t0\t0\n",
      "I1\t0\t0.800\t0\t0\t0.200\n",
      "M2\t0\t0\t0\t0\t0\n",
      "D2\t0.143\t0\t0\t0.714\t0.143\n",
      "I2\t0\t0\t0\t0\t0\n",
      "E\t0\t0\t0\t0\t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def construct_profile_hmm(alignment, alphabet, theta):\n",
    "    # Preprocess the alignment\n",
    "    alignment = [list(seq) for seq in alignment]\n",
    "    n_seqs = len(alignment)\n",
    "    seq_length = len(alignment[0])\n",
    "\n",
    "    # Count the number of non-gap characters in each column\n",
    "    col_counts = [sum(1 for seq in alignment if seq[i] != '-') for i in range(seq_length)]\n",
    "\n",
    "    # Determine which columns are matches (M) and which are inserts (I)\n",
    "    match_columns = [i for i, count in enumerate(col_counts) if count / n_seqs > theta]\n",
    "\n",
    "    # Initialize transition and emission matrices\n",
    "    n_match_states = len(match_columns)\n",
    "    n_states = 2 * n_match_states + 3  # S, I0, M1, D1, I1, ..., Mn, Dn, In, E\n",
    "    transitions = np.zeros((n_states, n_states))\n",
    "    emissions = np.zeros((n_states, len(alphabet)))\n",
    "\n",
    "    # Helper function to get state index\n",
    "    def state_index(state_type, state_num):\n",
    "        if state_type == 'S':\n",
    "            return 0\n",
    "        elif state_type == 'I':\n",
    "            return 2 * state_num + 1\n",
    "        elif state_type == 'M':\n",
    "            return 2 * state_num\n",
    "        elif state_type == 'D':\n",
    "            return 2 * state_num + 1\n",
    "        elif state_type == 'E':\n",
    "            return n_states - 1\n",
    "\n",
    "    # Count transitions and emissions\n",
    "    for seq in alignment:\n",
    "        prev_state = 'S'\n",
    "        prev_state_num = 0\n",
    "\n",
    "        for i, char in enumerate(seq):\n",
    "            if i in match_columns:\n",
    "                state_num = match_columns.index(i) + 1\n",
    "                if char == '-':\n",
    "                    state_type = 'D'\n",
    "                else:\n",
    "                    state_type = 'M'\n",
    "                    emissions[state_index('M', state_num)][alphabet.index(char)] += 1\n",
    "            else:\n",
    "                state_num = sum(1 for col in match_columns if col < i)\n",
    "                if char != '-':\n",
    "                    state_type = 'I'\n",
    "                    emissions[state_index('I', state_num)][alphabet.index(char)] += 1\n",
    "                else:\n",
    "                    continue  # Skip gaps in insert columns\n",
    "\n",
    "            transitions[state_index(prev_state, prev_state_num)][state_index(state_type, state_num)] += 1\n",
    "            prev_state, prev_state_num = state_type, state_num\n",
    "\n",
    "        # Transition to end state\n",
    "        transitions[state_index(prev_state, prev_state_num)][state_index('E', 0)] += 1\n",
    "\n",
    "    # Normalize transitions and emissions\n",
    "    for i in range(n_states):\n",
    "        row_sum = np.sum(transitions[i])\n",
    "        if row_sum > 0:\n",
    "            transitions[i] /= row_sum\n",
    "\n",
    "    for i in range(n_states):\n",
    "        row_sum = np.sum(emissions[i])\n",
    "        if row_sum > 0:\n",
    "            emissions[i] /= row_sum\n",
    "\n",
    "    return transitions, emissionse add k + 1 insertion states, denoted Insertion(0), . . . , Insertion(k) (see figure below). Entering Insertion(i) allows the profile HMM to emit an additional symbol after visiting the i-th column of Profile(Alignment∗) and before entering the (i + 1)- th column. Thus, we will connect Match(i) to Insertion(i) and Insertion(i) to Match(i + 1). Furthermore, to allow for multiple inserted symbols between columns of Profile(Alignment∗), we will connect Insertion(i) to itself.\n",
    "\n",
    "\n",
    "\n",
    "def format_matrix(matrix, row_labels, col_labels):\n",
    "    output = \"\\t\" + \"\\t\".join(col_labels) + \"\\n\"\n",
    "    for i, row in enumerate(matrix):\n",
    "        output += f\"{row_labels[i]}\\t\" + \"\\t\".join(f\"{x:.3f}\" if x > 0 else \"0\" for x in row) + \"\\n\"\n",
    "    return output\n",
    "\n",
    "# Main function to process input and generate output\n",
    "def main():\n",
    "    # Hardcoded input\n",
    "    input_data = \"\"\"0.289\n",
    "--------\n",
    "A B C D E\n",
    "--------\n",
    "EBA\n",
    "E-D\n",
    "EB-\n",
    "EED\n",
    "EBD\n",
    "EBE\n",
    "E-D\n",
    "E-D\"\"\"\n",
    "\n",
    "    # Process input\n",
    "    lines = input_data.strip().split('\\n')\n",
    "    theta = float(lines[0])\n",
    "    alphabet = lines[2].split()\n",
    "    alignment = lines[4:]\n",
    "\n",
    "    # Construct the profile HMM\n",
    "    transitions, emissions = construct_profile_hmm(alignment, alphabet, theta)\n",
    "\n",
    "    # Prepare labels for output\n",
    "    n_match_states = (transitions.shape[0] - 3) // 2\n",
    "    state_labels = ['S', 'I0'] + sum([[f'M{i}', f'D{i}', f'I{i}'] for i in range(1, n_match_states)], []) + ['E']\n",
    "\n",
    "    # Format and print the output\n",
    "    print(format_matrix(transitions, state_labels, state_labels))\n",
    "    print(\"--------\")\n",
    "    print(format_matrix(emissions, state_labels, alphabet))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t129\t125\t43\t51\t223\t86\t36\t45\t241\t197\t31\t260\t282\t148\t229\t75\t286\t277\t162\t192\t274\t69\t216\t98\t156\t254\t118\t185\t211\t138\t34\n",
      "129\t0\t32\t148\t88\t114\t63\t117\t112\t132\t88\t136\t151\t173\t39\t120\t72\t177\t168\t53\t83\t165\t88\t107\t47\t47\t145\t39\t76\t102\t29\t139\n",
      "125\t32\t0\t144\t84\t126\t59\t113\t108\t144\t100\t132\t163\t185\t51\t132\t68\t189\t180\t65\t95\t177\t84\t119\t43\t59\t157\t35\t88\t114\t41\t135\n",
      "43\t148\t144\t0\t70\t242\t105\t55\t64\t260\t216\t30\t279\t301\t167\t248\t94\t305\t296\t181\t211\t293\t88\t235\t117\t175\t273\t137\t204\t230\t157\t19\n",
      "51\t88\t84\t70\t0\t182\t45\t39\t34\t200\t156\t58\t219\t241\t107\t188\t34\t245\t236\t121\t151\t233\t28\t175\t57\t115\t213\t77\t144\t170\t97\t61\n",
      "223\t114\t126\t242\t182\t0\t157\t211\t206\t32\t44\t230\t51\t73\t101\t20\t166\t77\t68\t71\t55\t65\t182\t21\t141\t83\t45\t133\t66\t42\t113\t233\n",
      "86\t63\t59\t105\t45\t157\t0\t74\t69\t175\t131\t93\t194\t216\t82\t163\t29\t220\t211\t96\t126\t208\t45\t150\t32\t90\t188\t52\t119\t145\t72\t96\n",
      "36\t117\t113\t55\t39\t211\t74\t0\t33\t229\t185\t43\t248\t270\t136\t217\t63\t274\t265\t150\t180\t262\t57\t204\t86\t144\t242\t106\t173\t199\t126\t46\n",
      "45\t112\t108\t64\t34\t206\t69\t33\t0\t224\t180\t52\t243\t265\t131\t212\t58\t269\t260\t145\t175\t257\t52\t199\t81\t139\t237\t101\t168\t194\t121\t55\n",
      "241\t132\t144\t260\t200\t32\t175\t229\t224\t0\t62\t248\t33\t55\t119\t28\t184\t59\t50\t89\t73\t47\t200\t39\t159\t101\t27\t151\t84\t60\t131\t251\n",
      "197\t88\t100\t216\t156\t44\t131\t185\t180\t62\t0\t204\t81\t103\t75\t50\t140\t107\t98\t45\t29\t95\t156\t37\t115\t57\t75\t107\t40\t32\t87\t207\n",
      "31\t136\t132\t30\t58\t230\t93\t43\t52\t248\t204\t0\t267\t289\t155\t236\t82\t293\t284\t169\t199\t281\t76\t223\t105\t163\t261\t125\t192\t218\t145\t21\n",
      "260\t151\t163\t279\t219\t51\t194\t248\t243\t33\t81\t267\t0\t34\t138\t47\t203\t38\t29\t108\t92\t26\t219\t58\t178\t120\t32\t170\t103\t79\t150\t270\n",
      "282\t173\t185\t301\t241\t73\t216\t270\t265\t55\t103\t289\t34\t0\t160\t69\t225\t34\t25\t130\t114\t32\t241\t80\t200\t142\t54\t192\t125\t101\t172\t292\n",
      "148\t39\t51\t167\t107\t101\t82\t136\t131\t119\t75\t155\t138\t160\t0\t107\t91\t164\t155\t40\t70\t152\t107\t94\t66\t34\t132\t58\t63\t89\t38\t158\n",
      "229\t120\t132\t248\t188\t20\t163\t217\t212\t28\t50\t236\t47\t69\t107\t0\t172\t73\t64\t77\t61\t61\t188\t27\t147\t89\t41\t139\t72\t48\t119\t239\n",
      "75\t72\t68\t94\t34\t166\t29\t63\t58\t184\t140\t82\t203\t225\t91\t172\t0\t229\t220\t105\t135\t217\t34\t159\t41\t99\t197\t61\t128\t154\t81\t85\n",
      "286\t177\t189\t305\t245\t77\t220\t274\t269\t59\t107\t293\t38\t34\t164\t73\t229\t0\t19\t134\t118\t36\t245\t84\t204\t146\t58\t196\t129\t105\t176\t296\n",
      "277\t168\t180\t296\t236\t68\t211\t265\t260\t50\t98\t284\t29\t25\t155\t64\t220\t19\t0\t125\t109\t27\t236\t75\t195\t137\t49\t187\t120\t96\t167\t287\n",
      "162\t53\t65\t181\t121\t71\t96\t150\t145\t89\t45\t169\t108\t130\t40\t77\t105\t134\t125\t0\t40\t122\t121\t64\t80\t22\t102\t72\t33\t59\t52\t172\n",
      "192\t83\t95\t211\t151\t55\t126\t180\t175\t73\t29\t199\t92\t114\t70\t61\t135\t118\t109\t40\t0\t106\t151\t48\t110\t52\t86\t102\t35\t43\t82\t202\n",
      "274\t165\t177\t293\t233\t65\t208\t262\t257\t47\t95\t281\t26\t32\t152\t61\t217\t36\t27\t122\t106\t0\t233\t72\t192\t134\t46\t184\t117\t93\t164\t284\n",
      "69\t88\t84\t88\t28\t182\t45\t57\t52\t200\t156\t76\t219\t241\t107\t188\t34\t245\t236\t121\t151\t233\t0\t175\t57\t115\t213\t77\t144\t170\t97\t79\n",
      "216\t107\t119\t235\t175\t21\t150\t204\t199\t39\t37\t223\t58\t80\t94\t27\t159\t84\t75\t64\t48\t72\t175\t0\t134\t76\t52\t126\t59\t35\t106\t226\n",
      "98\t47\t43\t117\t57\t141\t32\t86\t81\t159\t115\t105\t178\t200\t66\t147\t41\t204\t195\t80\t110\t192\t57\t134\t0\t74\t172\t36\t103\t129\t56\t108\n",
      "156\t47\t59\t175\t115\t83\t90\t144\t139\t101\t57\t163\t120\t142\t34\t89\t99\t146\t137\t22\t52\t134\t115\t76\t74\t0\t114\t66\t45\t71\t46\t166\n",
      "254\t145\t157\t273\t213\t45\t188\t242\t237\t27\t75\t261\t32\t54\t132\t41\t197\t58\t49\t102\t86\t46\t213\t52\t172\t114\t0\t164\t97\t73\t144\t264\n",
      "118\t39\t35\t137\t77\t133\t52\t106\t101\t151\t107\t125\t170\t192\t58\t139\t61\t196\t187\t72\t102\t184\t77\t126\t36\t66\t164\t0\t95\t121\t48\t128\n",
      "185\t76\t88\t204\t144\t66\t119\t173\t168\t84\t40\t192\t103\t125\t63\t72\t128\t129\t120\t33\t35\t117\t144\t59\t103\t45\t97\t95\t0\t54\t75\t195\n",
      "211\t102\t114\t230\t170\t42\t145\t199\t194\t60\t32\t218\t79\t101\t89\t48\t154\t105\t96\t59\t43\t93\t170\t35\t129\t71\t73\t121\t54\t0\t101\t221\n",
      "138\t29\t41\t157\t97\t113\t72\t126\t121\t131\t87\t145\t150\t172\t38\t119\t81\t176\t167\t52\t82\t164\t97\t106\t56\t46\t144\t48\t75\t101\t0\t148\n",
      "34\t139\t135\t19\t61\t233\t96\t46\t55\t251\t207\t21\t270\t292\t158\t239\t85\t296\t287\t172\t202\t284\t79\t226\t108\t166\t264\t128\t195\t221\t148\t0\n"
     ]
    }
   ],
   "source": [
    "def build_graph(edges):\n",
    "    # Create adjacency list representation with weights\n",
    "    graph = {}\n",
    "    for edge in edges:\n",
    "        source, dest_weight = edge.split('->')\n",
    "        dest, weight = dest_weight.split(':')\n",
    "        source, dest, weight = int(source), int(dest), int(weight)\n",
    "        \n",
    "        # Initialize dict entries if they don't exist\n",
    "        if source not in graph:\n",
    "            graph[source] = {}\n",
    "        if dest not in graph:\n",
    "            graph[dest] = {}\n",
    "            \n",
    "        # Add edges (undirected graph)\n",
    "        graph[source][dest] = weight\n",
    "        graph[dest][source] = weight\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def find_path_length(graph, start, end, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    \n",
    "    # If we reached the destination\n",
    "    if start == end:\n",
    "        return 0\n",
    "    \n",
    "    visited.add(start)\n",
    "    min_length = float('inf')\n",
    "    \n",
    "    # Try all possible next nodes\n",
    "    for next_node in graph[start]:\n",
    "        if next_node not in visited:\n",
    "            length = find_path_length(graph, next_node, end, visited)\n",
    "            if length != float('inf'):\n",
    "                min_length = min(min_length, length + graph[start][next_node])\n",
    "                \n",
    "    visited.remove(start)\n",
    "    return min_length\n",
    "\n",
    "def compute_distances(n, edges):\n",
    "    # Build the graph\n",
    "    graph = build_graph(edges)\n",
    "    \n",
    "    # Initialize distance matrix\n",
    "    distances = [[0] * n for _ in range(n)]\n",
    "    \n",
    "    # Compute distances between all pairs of leaves\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):  # Only compute upper triangle\n",
    "            dist = find_path_length(graph, i, j)\n",
    "            distances[i][j] = dist\n",
    "            distances[j][i] = dist  # Matrix is symmetric\n",
    "    \n",
    "    return distances\n",
    "\n",
    "def main():\n",
    "    # Read input from file\n",
    "    with open('data/dataset_39959_12.txt', 'r') as file:\n",
    "        # Read number of leaves\n",
    "        n = int(file.readline().strip())\n",
    "        \n",
    "        # Read edges\n",
    "        edges = []\n",
    "        for line in file:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                edges.append(line.strip())\n",
    "    \n",
    "    # Compute distances\n",
    "    distances = compute_distances(n, edges)\n",
    "    \n",
    "    # Print output\n",
    "    for row in distances:\n",
    "        print('\\t'.join(map(str, row)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521\n"
     ]
    }
   ],
   "source": [
    "def limb_length(n, j, D):\n",
    "    # Initialize minimum length as infinity\n",
    "    min_length = float('inf')\n",
    "    \n",
    "    # Try all pairs of leaves i and k where i ≠ j and k ≠ j\n",
    "    for i in range(n):\n",
    "        if i == j:\n",
    "            continue\n",
    "        for k in range(i + 1, n):  # k > i to avoid counting pairs twice\n",
    "            if k == j:\n",
    "                continue\n",
    "            \n",
    "            # Calculate (Di,j + Dj,k - Di,k)/2\n",
    "            length = (D[i][j] + D[j][k] - D[i][k]) / 2\n",
    "            min_length = min(min_length, length)\n",
    "    \n",
    "    return int(min_length)  # Convert to integer as per problem requirements\n",
    "\n",
    "def main():\n",
    "    # Read input from file\n",
    "    with open('data/dataset_39960_8.txt', 'r') as file:\n",
    "        # Read n\n",
    "        n = int(file.readline().strip())\n",
    "        \n",
    "        # Read j\n",
    "        j = int(file.readline().strip())\n",
    "        \n",
    "        # Read distance matrix\n",
    "        D = []\n",
    "        for _ in range(n):\n",
    "            row = list(map(int, file.readline().strip().split()))\n",
    "            D.append(row)\n",
    "    \n",
    "    # Calculate limb length\n",
    "    result = limb_length(n, j, D)\n",
    "    \n",
    "    # Print result\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0->22:222.50\n",
      "1->28:239.50\n",
      "2->24:227.00\n",
      "3->25:231.00\n",
      "4->25:231.00\n",
      "5->26:231.50\n",
      "6->23:223.50\n",
      "7->30:257.50\n",
      "8->27:239.00\n",
      "9->30:257.50\n",
      "10->22:222.50\n",
      "11->24:227.00\n",
      "12->21:220.50\n",
      "13->33:286.25\n",
      "14->23:223.50\n",
      "15->28:239.50\n",
      "16->26:231.50\n",
      "17->27:239.00\n",
      "18->32:284.75\n",
      "19->29:255.25\n",
      "20->21:220.50\n",
      "21->12:220.50\n",
      "21->20:220.50\n",
      "21->31:47.12\n",
      "22->0:222.50\n",
      "22->10:222.50\n",
      "22->34:69.62\n",
      "23->6:223.50\n",
      "23->14:223.50\n",
      "23->29:31.75\n",
      "24->2:227.00\n",
      "24->11:227.00\n",
      "24->34:65.12\n",
      "25->3:231.00\n",
      "25->4:231.00\n",
      "25->40:117.68\n",
      "26->5:231.50\n",
      "26->16:231.50\n",
      "26->35:77.94\n",
      "27->8:239.00\n",
      "27->17:239.00\n",
      "27->33:47.25\n",
      "28->1:239.50\n",
      "28->15:239.50\n",
      "28->31:28.12\n",
      "29->19:255.25\n",
      "29->23:31.75\n",
      "29->37:74.01\n",
      "30->7:257.50\n",
      "30->9:257.50\n",
      "30->32:27.25\n",
      "31->21:47.12\n",
      "31->28:28.12\n",
      "31->36:45.38\n",
      "32->18:284.75\n",
      "32->30:27.25\n",
      "32->36:28.25\n",
      "33->13:286.25\n",
      "33->27:47.25\n",
      "33->39:56.55\n",
      "34->22:69.62\n",
      "34->24:65.12\n",
      "34->35:17.31\n",
      "35->26:77.94\n",
      "35->34:17.31\n",
      "35->38:27.07\n",
      "36->31:45.38\n",
      "36->32:28.25\n",
      "36->37:16.26\n",
      "37->29:74.01\n",
      "37->36:16.26\n",
      "37->38:7.25\n",
      "38->35:27.07\n",
      "38->37:7.25\n",
      "38->39:6.29\n",
      "39->33:56.55\n",
      "39->38:6.29\n",
      "39->40:5.88\n",
      "40->25:117.68\n",
      "40->39:5.88\n"
     ]
    }
   ],
   "source": [
    "def parse_input(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        n = int(file.readline().strip())\n",
    "        D = []\n",
    "        for _ in range(n):\n",
    "            row = list(map(float, file.readline().strip().split()))\n",
    "            D.append(row)\n",
    "    return D, n\n",
    "\n",
    "def find_closest_clusters(D):\n",
    "    n = len(D)\n",
    "    min_dist = float('inf')\n",
    "    min_i = min_j = -1\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if D[i][j] < min_dist:\n",
    "                min_dist = D[i][j]\n",
    "                min_i, min_j = i, j\n",
    "    \n",
    "    return min_i, min_j, min_dist\n",
    "\n",
    "def compute_new_distances(D, ci_idx, cj_idx, cluster_sizes):\n",
    "    n = len(D)\n",
    "    new_distances = []\n",
    "    ci_size = cluster_sizes[ci_idx]\n",
    "    cj_size = cluster_sizes[cj_idx]\n",
    "    \n",
    "    for k in range(n):\n",
    "        if k != ci_idx and k != cj_idx:\n",
    "            # Get distances using correct indices\n",
    "            ci_dist = D[min(ci_idx, k)][max(ci_idx, k)]\n",
    "            cj_dist = D[min(cj_idx, k)][max(cj_idx, k)]\n",
    "            # Weighted average formula\n",
    "            new_dist = (ci_dist * ci_size + cj_dist * cj_size) / (ci_size + cj_size)\n",
    "            new_distances.append(new_dist)\n",
    "    \n",
    "    return new_distances\n",
    "\n",
    "def update_distance_matrix(D, ci_idx, cj_idx, new_distances):\n",
    "    n = len(D)\n",
    "    # Create new matrix excluding merged clusters\n",
    "    new_D = []\n",
    "    for i in range(n):\n",
    "        if i != ci_idx and i != cj_idx:\n",
    "            row = []\n",
    "            for j in range(n):\n",
    "                if j != ci_idx and j != cj_idx:\n",
    "                    row.append(D[i][j])\n",
    "            new_D.append(row)\n",
    "    \n",
    "    # Add new distances\n",
    "    for i in range(len(new_D)):\n",
    "        new_D[i].append(new_distances[i])\n",
    "    new_D.append(new_distances + [0.0])\n",
    "    \n",
    "    return new_D\n",
    "\n",
    "def upgma(D, n):\n",
    "    # Initialize\n",
    "    active_nodes = list(range(n))\n",
    "    cluster_sizes = [1] * n\n",
    "    ages = {i: 0.0 for i in range(n)}\n",
    "    edges = {}\n",
    "    next_node = n\n",
    "    \n",
    "    while len(D) > 1:\n",
    "        # Find closest clusters\n",
    "        ci_idx, cj_idx, dist = find_closest_clusters(D)\n",
    "        ci = active_nodes[ci_idx]\n",
    "        cj = active_nodes[cj_idx]\n",
    "        \n",
    "        # Create new node\n",
    "        new_node = next_node\n",
    "        next_node += 1\n",
    "        \n",
    "        # Set age of new node\n",
    "        ages[new_node] = dist / 2\n",
    "        \n",
    "        # Add edges\n",
    "        edges[(new_node, ci)] = ages[new_node] - ages[ci]\n",
    "        edges[(new_node, cj)] = ages[new_node] - ages[cj]\n",
    "        edges[(ci, new_node)] = edges[(new_node, ci)]\n",
    "        edges[(cj, new_node)] = edges[(new_node, cj)]\n",
    "        \n",
    "        # Calculate new distances before updating cluster sizes\n",
    "        new_distances = compute_new_distances(D, ci_idx, cj_idx, cluster_sizes)\n",
    "        \n",
    "        # Update cluster sizes\n",
    "        new_size = cluster_sizes[ci_idx] + cluster_sizes[cj_idx]\n",
    "        cluster_sizes = [size for idx, size in enumerate(cluster_sizes) \n",
    "                        if idx != ci_idx and idx != cj_idx]\n",
    "        cluster_sizes.append(new_size)\n",
    "        \n",
    "        # Update distance matrix\n",
    "        D = update_distance_matrix(D, ci_idx, cj_idx, new_distances)\n",
    "        \n",
    "        # Update active nodes\n",
    "        active_nodes = [node for idx, node in enumerate(active_nodes) \n",
    "                       if idx != ci_idx and idx != cj_idx]\n",
    "        active_nodes.append(new_node)\n",
    "    \n",
    "    # Print edges with 2 decimal places\n",
    "    for (u, v), length in sorted(edges.items()):\n",
    "        print(f\"{u}->{v}:{length:.2f}\")\n",
    "\n",
    "def main():\n",
    "    filename = 'data/dataset_39963_8 (4).txt'\n",
    "    D, n = parse_input(filename)\n",
    "    upgma(D, n)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        n = int(file.readline().strip())\n",
    "        D = []\n",
    "        for _ in range(n):\n",
    "            row = list(map(float, file.readline().strip().split()))\n",
    "            D.append(row)\n",
    "    return D, n\n",
    "\n",
    "def total_distance(D, i):\n",
    "    \"\"\"Calculate total distance from node i to all other nodes\"\"\"\n",
    "    return sum(D[i][j] for j in range(len(D)))\n",
    "\n",
    "def create_neighbor_joining_matrix(D):\n",
    "    \"\"\"Create neighbor-joining matrix D* from distance matrix D\"\"\"\n",
    "    n = len(D)\n",
    "    D_star = [[0.0] * n for _ in range(n)]\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                total_dist_i = total_distance(D, i)\n",
    "                total_dist_j = total_distance(D, j)\n",
    "                D_star[i][j] = (n - 2) * D[i][j] - total_dist_i - total_dist_j\n",
    "    \n",
    "    return D_star\n",
    "\n",
    "def find_minimum_element(D_star):\n",
    "    \"\"\"Find minimum non-diagonal element in D* matrix\"\"\"\n",
    "    n = len(D_star)\n",
    "    min_val = float('inf')\n",
    "    min_i = min_j = -1\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if D_star[i][j] < min_val:\n",
    "                min_val = D_star[i][j]\n",
    "                min_i, min_j = i, j\n",
    "    \n",
    "    return min_i, min_j\n",
    "\n",
    "def update_distance_matrix(D, i, j):\n",
    "    \"\"\"Create new distance matrix with merged node m\"\"\"\n",
    "    n = len(D)\n",
    "    m_distances = []\n",
    "    \n",
    "    # Calculate distances to new node m\n",
    "    for k in range(n):\n",
    "        if k != i and k != j:\n",
    "            dist_k_m = (D[k][i] + D[k][j] - D[i][j]) / 2\n",
    "            m_distances.append(dist_k_m)\n",
    "    \n",
    "    # Create new matrix without i and j, but with new node m\n",
    "    new_D = []\n",
    "    for row in range(n):\n",
    "        if row != i and row != j:\n",
    "            new_row = []\n",
    "            for col in range(n):\n",
    "                if col != i and col != j:\n",
    "                    new_row.append(D[row][col])\n",
    "            new_D.append(new_row)\n",
    "    \n",
    "    # Add row and column for m\n",
    "    for row in range(len(new_D)):\n",
    "        new_D[row].append(m_distances[row])\n",
    "    new_D.append(m_distances + [0.0])\n",
    "    \n",
    "    return new_D\n",
    "\n",
    "def neighbor_joining(D, current_nodes, next_node):\n",
    "    n = len(D)\n",
    "    \n",
    "    # Base case: only two nodes left\n",
    "    if n == 2:\n",
    "        edges = {\n",
    "            (current_nodes[0], next_node): D[0][1]/2,\n",
    "            (current_nodes[1], next_node): D[0][1]/2,\n",
    "            (next_node, current_nodes[0]): D[0][1]/2,\n",
    "            (next_node, current_nodes[1]): D[0][1]/2\n",
    "        }\n",
    "        return edges, next_node + 1\n",
    "    \n",
    "    # Create neighbor-joining matrix\n",
    "    D_star = create_neighbor_joining_matrix(D)\n",
    "    \n",
    "    # Find minimum element\n",
    "    i, j = find_minimum_element(D_star)\n",
    "    \n",
    "    # Calculate delta\n",
    "    total_dist_i = total_distance(D, i)\n",
    "    total_dist_j = total_distance(D, j)\n",
    "    delta = (total_dist_i - total_dist_j) / (n - 2)\n",
    "    \n",
    "    # Calculate limb lengths\n",
    "    limb_length_i = (D[i][j] + delta) / 2\n",
    "    limb_length_j = (D[i][j] - delta) / 2\n",
    "    \n",
    "    # Update distance matrix\n",
    "    new_D = update_distance_matrix(D, i, j)\n",
    "    \n",
    "    # Save current nodes i and j\n",
    "    node_i = current_nodes[i]\n",
    "    node_j = current_nodes[j]\n",
    "    \n",
    "    # Update current_nodes list\n",
    "    new_current_nodes = [node for k, node in enumerate(current_nodes) if k != i and k != j]\n",
    "    new_current_nodes.append(next_node)\n",
    "    \n",
    "    # Recursive call\n",
    "    edges, next_next_node = neighbor_joining(new_D, new_current_nodes, next_node + 1)\n",
    "    \n",
    "    # Add new edges\n",
    "    edges[(next_node, node_i)] = limb_length_i\n",
    "    edges[(next_node, node_j)] = limb_length_j\n",
    "    edges[(node_i, next_node)] = limb_length_i\n",
    "    edges[(node_j, next_node)] = limb_length_j\n",
    "    \n",
    "    return edges, next_next_node\n",
    "\n",
    "def main():\n",
    "    filename = 'data/dataset_39964_6.txt'\n",
    "    D, n = parse_input(filename)\n",
    "    \n",
    "    # Initialize with leaf nodes 0 to n-1\n",
    "    current_nodes = list(range(n))\n",
    "    next_node = n\n",
    "    \n",
    "    # Run neighbor joining algorithm\n",
    "    edges, _ = neighbor_joining(D, current_nodes, next_node)\n",
    "    \n",
    "    # Print edges in required format\n",
    "    for (u, v), length in sorted(edges.items()):\n",
    "        print(f\"{u}->{v}:{length:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aispace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
