{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "# generate a random DNA sequence of length 10000bp\n",
    "def generate_random_sequence(length):\n",
    "    dna = \"\"\n",
    "    for i in range(length):\n",
    "        dna += random.choice(\"ACGT\")\n",
    "    return dna\n",
    "\n",
    "# generate a random DNA sequence of length 10000bp\n",
    "dna = generate_random_sequence(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import List, Dict, Iterable\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# ------------------------ Generate Reads ------------------------ #\n",
    "def generate_reads(dna: str, read_len: int, coverage: float) -> List[str]:\n",
    "    \"\"\"Generates reads from a DNA string with specified read length and coverage.\"\"\"\n",
    "    genome_len = len(dna)\n",
    "    num_reads = int(genome_len * coverage / read_len)\n",
    "    reads = []\n",
    "    for _ in range(num_reads):\n",
    "        start_pos = random.randint(0, genome_len - read_len)\n",
    "        reads.append(dna[start_pos:start_pos + read_len])\n",
    "    return reads\n",
    "\n",
    "# ------------------------ Break Reads into k-mers ------------------------ #\n",
    "def break_reads_into_kmers(reads: List[str], k: int, g: int) -> List[str]:\n",
    "    \"\"\"Breaks a list of reads into k-mers with a gap of g.\"\"\"\n",
    "    kmers = []\n",
    "    for read in reads:\n",
    "        for i in range(0, len(read) - k + 1, g + 1):  # Step by g+1\n",
    "            kmers.append(read[i:i+k])\n",
    "    return kmers\n",
    "\n",
    "# ------------------------ De Bruijn Graph from k-mers ------------------------ #\n",
    "def de_bruijn_kmers(k_mers: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"Forms the de Bruijn graph of a collection of k-mers.\"\"\"\n",
    "    adj_list = defaultdict(list)\n",
    "    for k_mer in k_mers:\n",
    "        prefix = k_mer[:-1]\n",
    "        suffix = k_mer[1:]\n",
    "        adj_list[prefix].append(suffix)\n",
    "    return dict(adj_list)\n",
    "\n",
    "# ------------------------ Eulerian Path ------------------------ #\n",
    "def extend_cycle(cycle: List[str], marked_graph: Dict[str, List[str]]) -> List[str]:\n",
    "    \"\"\"Extends the Eulerian cycle from a given node in the marked graph.\"\"\"\n",
    "    if cycle:\n",
    "        cycle.pop()  # remove the repeated node at the end\n",
    "        new_start_index = next(i for i, node in enumerate(cycle) if node in marked_graph)\n",
    "        cycle = cycle[new_start_index:] + cycle[:new_start_index]\n",
    "        cycle.append(cycle[0])  # re-add the repeated node\n",
    "        current_node = cycle[-1]\n",
    "    else:\n",
    "        current_node = next(iter(marked_graph))  # get an arbitrary node from the graph\n",
    "        cycle = [current_node]\n",
    "    \n",
    "    while current_node in marked_graph:\n",
    "        old_node = current_node\n",
    "        current_node = marked_graph[old_node].pop()\n",
    "        if not marked_graph[old_node]:\n",
    "            del marked_graph[old_node]  # remove the node if no more edges\n",
    "        cycle.append(current_node)\n",
    "    \n",
    "    return cycle\n",
    "\n",
    "def eulerian_cycle_str(g: Dict[str, List[str]]) -> List[str]:\n",
    "    \"\"\"Constructs an Eulerian cycle in a graph. Assumes the graph is Eulerian and connected.\"\"\"\n",
    "    cycle = []\n",
    "    while g:\n",
    "        cycle = extend_cycle(cycle, g)\n",
    "    return cycle\n",
    "\n",
    "def fix_unbalanced(g: Dict[str, List[str]]) -> tuple[str, str]:\n",
    "    \"\"\"Finds and fixes unbalanced nodes in the graph.\"\"\"\n",
    "    total_degree = defaultdict(int)\n",
    "    \n",
    "    for node1, adj_nodes in g.items():\n",
    "        for node2 in adj_nodes:\n",
    "            total_degree[node1] += 1  # Out-degree\n",
    "            total_degree[node2] -= 1  # In-degree\n",
    "\n",
    "    s, t = None, None\n",
    "    for node, tot_degree in total_degree.items():\n",
    "        if tot_degree == 1:\n",
    "            t = node\n",
    "        elif tot_degree== -1:\n",
    "            s = node\n",
    "\n",
    "    if s and t:\n",
    "        g.setdefault(s, []).append(t)\n",
    "    \n",
    "    return s, t\n",
    "\n",
    "def eulerian_path(g: Dict[str, List[str]]) -> List[str]:\n",
    "    \"\"\"Constructs an Eulerian path in a graph, assuming the graph is nearly Eulerian.\"\"\"\n",
    "    s, t = fix_unbalanced(g)\n",
    "    cycle = eulerian_cycle_str(g)\n",
    "    \n",
    "    if s:\n",
    "        cycle.pop()  # Remove the duplicate last node\n",
    "        t_index = next(i for i, (u, v) in enumerate(zip(cycle, cycle[1:])) if u == s and v == t)\n",
    "        cycle = cycle[t_index + 1:] + cycle[:t_index + 1]\n",
    "    \n",
    "    return cycle\n",
    "\n",
    "# ------------------------ String Spelled by a Genome Path ------------------------ #\n",
    "def genome_path(path: List[str]) -> str:\n",
    "    \"\"\"Forms the genome path formed by a collection of patterns.\"\"\"\n",
    "    if not path:\n",
    "        return \"\"\n",
    "    result = path[0]\n",
    "    for i in range(1, len(path)):\n",
    "        result += path[i][-1]\n",
    "    return result\n",
    "\n",
    "# ------------------------ Assemble Sequence ------------------------ #\n",
    "def assemble_sequence(dna: str, read_len: int, coverage: float, k: int, g: int) -> str:\n",
    "    \"\"\"Assembles a DNA sequence from reads using a De Bruijn graph.\"\"\"\n",
    "    reads = generate_reads(dna, read_len, coverage)\n",
    "    kmers = break_reads_into_kmers(reads, k, g)  # Pass g here\n",
    "    graph = de_bruijn_kmers(kmers)\n",
    "    path = eulerian_path(graph)\n",
    "    assembled_sequence = genome_path(path)\n",
    "    return assembled_sequence\n",
    "\n",
    "# # ------------------------ Main Execution ------------------------ #\n",
    "# if __name__ == \"__main__\":\n",
    "#     dna_string = input(\"Enter DNA string: \")\n",
    "#     read_length = int(input(\"Enter read length: \"))\n",
    "#     coverage_percentage = float(input(\"Enter coverage percentage (e.g., 0.5 for 50%): \"))\n",
    "#     kmer_length = int(input(\"Enter k-mer length: \"))\n",
    "\n",
    "#     assembled_dna = assemble_sequence(dna_string, read_length, coverage_percentage, kmer_length)\n",
    "#     print(\"Assembled DNA sequence:\", assembled_dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m kmer_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      5\u001b[0m gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 7\u001b[0m assembled_dna \u001b[38;5;241m=\u001b[39m \u001b[43massemble_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdna_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoverage_percentage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkmer_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 114\u001b[0m, in \u001b[0;36massemble_sequence\u001b[1;34m(dna, read_len, coverage, k, g)\u001b[0m\n\u001b[0;32m    112\u001b[0m kmers \u001b[38;5;241m=\u001b[39m break_reads_into_kmers(reads, k, g)  \u001b[38;5;66;03m# Pass g here\u001b[39;00m\n\u001b[0;32m    113\u001b[0m graph \u001b[38;5;241m=\u001b[39m de_bruijn_kmers(kmers)\n\u001b[1;32m--> 114\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43meulerian_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m assembled_sequence \u001b[38;5;241m=\u001b[39m genome_path(path)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m assembled_sequence\n",
      "Cell \u001b[1;32mIn[19], line 89\u001b[0m, in \u001b[0;36meulerian_path\u001b[1;34m(g)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an Eulerian path in a graph, assuming the graph is nearly Eulerian.\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m s, t \u001b[38;5;241m=\u001b[39m fix_unbalanced(g)\n\u001b[1;32m---> 89\u001b[0m cycle \u001b[38;5;241m=\u001b[39m \u001b[43meulerian_cycle_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s:\n\u001b[0;32m     92\u001b[0m     cycle\u001b[38;5;241m.\u001b[39mpop()  \u001b[38;5;66;03m# Remove the duplicate last node\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 62\u001b[0m, in \u001b[0;36meulerian_cycle_str\u001b[1;34m(g)\u001b[0m\n\u001b[0;32m     60\u001b[0m cycle \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m g:\n\u001b[1;32m---> 62\u001b[0m     cycle \u001b[38;5;241m=\u001b[39m \u001b[43mextend_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cycle\n",
      "Cell \u001b[1;32mIn[19], line 41\u001b[0m, in \u001b[0;36mextend_cycle\u001b[1;34m(cycle, marked_graph)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cycle:\n\u001b[0;32m     40\u001b[0m     cycle\u001b[38;5;241m.\u001b[39mpop()  \u001b[38;5;66;03m# remove the repeated node at the end\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     new_start_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmarked_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     cycle \u001b[38;5;241m=\u001b[39m cycle[new_start_index:] \u001b[38;5;241m+\u001b[39m cycle[:new_start_index]\n\u001b[0;32m     43\u001b[0m     cycle\u001b[38;5;241m.\u001b[39mappend(cycle[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# re-add the repeated node\u001b[39;00m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dna_string = generate_random_sequence(1000)\n",
    "read_length = 20\n",
    "coverage_percentage = 1.0\n",
    "kmer_length = 10\n",
    "gap = 1\n",
    "\n",
    "assembled_dna = assemble_sequence(dna_string, read_length, coverage_percentage, kmer_length, gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tS\tI0\tM1\tD1\tI1\tM2\tD2\tI2\tM3\tD3\tI3\tE\n",
      "S\t0\t0\t1.000\t0\t0\t0\t0\t0\t0\n",
      "I0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "M1\t0\t0\t0\t0\t0.714\t0.286\t0\t0\t0\n",
      "D1\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I1\t0\t0\t0\t0\t0\t0\t0.800\t0.200\t0\n",
      "M2\t0\t0\t0\t0\t0\t0\t1.000\t0\t0\n",
      "D2\t0\t0\t0\t0\t0\t0\t0\t0\t1.000\n",
      "I2\t0\t0\t0\t0\t0\t0\t0\t0\t1.000\n",
      "M3\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "\n",
      "--------\n",
      "\tA\tB\tC\tD\tE\n",
      "S\t0\t0\t0\t0\t0\n",
      "I0\t0\t0\t0\t0\t0\n",
      "M1\t0\t0\t0\t0\t1.000\n",
      "D1\t0\t0\t0\t0\t0\n",
      "I1\t0\t0.800\t0\t0\t0.200\n",
      "M2\t0\t0\t0\t0\t0\n",
      "D2\t0.167\t0\t0\t0.667\t0.167\n",
      "I2\t0\t0\t0\t0\t0\n",
      "M3\t0\t0\t0\t0\t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def construct_profile_hmm(alignment, alphabet, theta):\n",
    "    # Preprocess the alignment\n",
    "    alignment = [list(seq) for seq in alignment]\n",
    "    n_seqs = len(alignment)\n",
    "    seq_length = len(alignment[0])\n",
    "    \n",
    "    # Count the number of non-gap characters in each column\n",
    "    col_counts = [sum(1 for seq in alignment if seq[i] != '-') for i in range(seq_length)]\n",
    "    \n",
    "    # Determine which columns are matches (M) and which are inserts (I)\n",
    "    match_columns = [i for i, count in enumerate(col_counts) if count / n_seqs > theta]\n",
    "    \n",
    "    # Initialize transition and emission matrices\n",
    "    n_match_states = len(match_columns)\n",
    "    n_states = 2 * n_match_states + 3  # S, I0, M1, D1, I1, ..., Mn, Dn, In, E\n",
    "    transitions = np.zeros((n_states, n_states))\n",
    "    emissions = np.zeros((n_states, len(alphabet)))\n",
    "    \n",
    "    # Helper function to get state index\n",
    "    def state_index(state_type, state_num):\n",
    "        if state_type == 'S':\n",
    "            return 0\n",
    "        elif state_type == 'I':\n",
    "            return 2 * state_num + 1\n",
    "        elif state_type == 'M':\n",
    "            return 2 * state_num\n",
    "        elif state_type == 'D':\n",
    "            return 2 * state_num + 1\n",
    "        elif state_type == 'E':\n",
    "            return n_states - 1\n",
    "    \n",
    "    # Count transitions and emissions\n",
    "    for seq in alignment:\n",
    "        prev_state = 'S'\n",
    "        prev_state_num = 0\n",
    "        \n",
    "        for i, char in enumerate(seq):\n",
    "            if i in match_columns:\n",
    "                state_num = match_columns.index(i) + 1\n",
    "                if char == '-':\n",
    "                    state_type = 'D'\n",
    "                else:\n",
    "                    state_type = 'M'\n",
    "                    emissions[state_index('M', state_num)][alphabet.index(char)] += 1\n",
    "            else:\n",
    "                state_num = sum(1 for col in match_columns if col < i)\n",
    "                if char != '-':\n",
    "                    state_type = 'I'\n",
    "                    emissions[state_index('I', state_num)][alphabet.index(char)] += 1\n",
    "                else:\n",
    "                    continue  # Skip gaps in insert columns\n",
    "            \n",
    "            transitions[state_index(prev_state, prev_state_num)][state_index(state_type, state_num)] += 1\n",
    "            prev_state, prev_state_num = state_type, state_num\n",
    "        \n",
    "        # Transition to end state\n",
    "        transitions[state_index(prev_state, prev_state_num)][state_index('E', 0)] += 1\n",
    "    \n",
    "    # Normalize transitions and emissions\n",
    "    for i in range(n_states):\n",
    "        row_sum = np.sum(transitions[i])\n",
    "        if row_sum > 0:\n",
    "            transitions[i] /= row_sum\n",
    "    \n",
    "    for i in range(n_states):\n",
    "        row_sum = np.sum(emissions[i])\n",
    "        if row_sum > 0:\n",
    "            emissions[i] /= row_sum\n",
    "    \n",
    "    return transitions, emissions\n",
    "\n",
    "def format_matrix(matrix, row_labels, col_labels):\n",
    "    output = \"\\t\" + \"\\t\".join(col_labels) + \"\\n\"\n",
    "    for i, row in enumerate(matrix):\n",
    "        output += f\"{row_labels[i]}\\t\" + \"\\t\".join(f\"{x:.3f}\" if x > 0 else \"0\" for x in row) + \"\\n\"\n",
    "    return output\n",
    "\n",
    "# Main function to process input and generate output\n",
    "def main():\n",
    "    # Hardcoded input\n",
    "    input_data = \"\"\"0.289\n",
    "--------\n",
    "A B C D E\n",
    "--------\n",
    "EBA\n",
    "E-D\n",
    "EB-\n",
    "EED\n",
    "EBD\n",
    "EBE\n",
    "E-D\n",
    "\"\"\"\n",
    "\n",
    "    # Process input\n",
    "    lines = input_data.strip().split('\\n')\n",
    "    theta = float(lines[0])\n",
    "    alphabet = lines[2].split()\n",
    "    alignment = [line.strip() for line in lines[4:]]\n",
    "\n",
    "    # Construct the profile HMM\n",
    "    transitions, emissions = construct_profile_hmm(alignment, alphabet, theta)\n",
    "\n",
    "    # Prepare labels for output\n",
    "    n_match_states = (transitions.shape[0] - 3) // 2\n",
    "    state_labels = ['S', 'I0'] + sum([[f'M{i}', f'D{i}', f'I{i}'] for i in range(1, n_match_states + 1)], []) + ['E']\n",
    "\n",
    "    # Format and print the output\n",
    "    print(format_matrix(transitions, state_labels, state_labels))\n",
    "    print(\"--------\")\n",
    "    print(format_matrix(emissions, state_labels, alphabet))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t129\t125\t43\t51\t223\t86\t36\t45\t241\t197\t31\t260\t282\t148\t229\t75\t286\t277\t162\t192\t274\t69\t216\t98\t156\t254\t118\t185\t211\t138\t34\n",
      "129\t0\t32\t148\t88\t114\t63\t117\t112\t132\t88\t136\t151\t173\t39\t120\t72\t177\t168\t53\t83\t165\t88\t107\t47\t47\t145\t39\t76\t102\t29\t139\n",
      "125\t32\t0\t144\t84\t126\t59\t113\t108\t144\t100\t132\t163\t185\t51\t132\t68\t189\t180\t65\t95\t177\t84\t119\t43\t59\t157\t35\t88\t114\t41\t135\n",
      "43\t148\t144\t0\t70\t242\t105\t55\t64\t260\t216\t30\t279\t301\t167\t248\t94\t305\t296\t181\t211\t293\t88\t235\t117\t175\t273\t137\t204\t230\t157\t19\n",
      "51\t88\t84\t70\t0\t182\t45\t39\t34\t200\t156\t58\t219\t241\t107\t188\t34\t245\t236\t121\t151\t233\t28\t175\t57\t115\t213\t77\t144\t170\t97\t61\n",
      "223\t114\t126\t242\t182\t0\t157\t211\t206\t32\t44\t230\t51\t73\t101\t20\t166\t77\t68\t71\t55\t65\t182\t21\t141\t83\t45\t133\t66\t42\t113\t233\n",
      "86\t63\t59\t105\t45\t157\t0\t74\t69\t175\t131\t93\t194\t216\t82\t163\t29\t220\t211\t96\t126\t208\t45\t150\t32\t90\t188\t52\t119\t145\t72\t96\n",
      "36\t117\t113\t55\t39\t211\t74\t0\t33\t229\t185\t43\t248\t270\t136\t217\t63\t274\t265\t150\t180\t262\t57\t204\t86\t144\t242\t106\t173\t199\t126\t46\n",
      "45\t112\t108\t64\t34\t206\t69\t33\t0\t224\t180\t52\t243\t265\t131\t212\t58\t269\t260\t145\t175\t257\t52\t199\t81\t139\t237\t101\t168\t194\t121\t55\n",
      "241\t132\t144\t260\t200\t32\t175\t229\t224\t0\t62\t248\t33\t55\t119\t28\t184\t59\t50\t89\t73\t47\t200\t39\t159\t101\t27\t151\t84\t60\t131\t251\n",
      "197\t88\t100\t216\t156\t44\t131\t185\t180\t62\t0\t204\t81\t103\t75\t50\t140\t107\t98\t45\t29\t95\t156\t37\t115\t57\t75\t107\t40\t32\t87\t207\n",
      "31\t136\t132\t30\t58\t230\t93\t43\t52\t248\t204\t0\t267\t289\t155\t236\t82\t293\t284\t169\t199\t281\t76\t223\t105\t163\t261\t125\t192\t218\t145\t21\n",
      "260\t151\t163\t279\t219\t51\t194\t248\t243\t33\t81\t267\t0\t34\t138\t47\t203\t38\t29\t108\t92\t26\t219\t58\t178\t120\t32\t170\t103\t79\t150\t270\n",
      "282\t173\t185\t301\t241\t73\t216\t270\t265\t55\t103\t289\t34\t0\t160\t69\t225\t34\t25\t130\t114\t32\t241\t80\t200\t142\t54\t192\t125\t101\t172\t292\n",
      "148\t39\t51\t167\t107\t101\t82\t136\t131\t119\t75\t155\t138\t160\t0\t107\t91\t164\t155\t40\t70\t152\t107\t94\t66\t34\t132\t58\t63\t89\t38\t158\n",
      "229\t120\t132\t248\t188\t20\t163\t217\t212\t28\t50\t236\t47\t69\t107\t0\t172\t73\t64\t77\t61\t61\t188\t27\t147\t89\t41\t139\t72\t48\t119\t239\n",
      "75\t72\t68\t94\t34\t166\t29\t63\t58\t184\t140\t82\t203\t225\t91\t172\t0\t229\t220\t105\t135\t217\t34\t159\t41\t99\t197\t61\t128\t154\t81\t85\n",
      "286\t177\t189\t305\t245\t77\t220\t274\t269\t59\t107\t293\t38\t34\t164\t73\t229\t0\t19\t134\t118\t36\t245\t84\t204\t146\t58\t196\t129\t105\t176\t296\n",
      "277\t168\t180\t296\t236\t68\t211\t265\t260\t50\t98\t284\t29\t25\t155\t64\t220\t19\t0\t125\t109\t27\t236\t75\t195\t137\t49\t187\t120\t96\t167\t287\n",
      "162\t53\t65\t181\t121\t71\t96\t150\t145\t89\t45\t169\t108\t130\t40\t77\t105\t134\t125\t0\t40\t122\t121\t64\t80\t22\t102\t72\t33\t59\t52\t172\n",
      "192\t83\t95\t211\t151\t55\t126\t180\t175\t73\t29\t199\t92\t114\t70\t61\t135\t118\t109\t40\t0\t106\t151\t48\t110\t52\t86\t102\t35\t43\t82\t202\n",
      "274\t165\t177\t293\t233\t65\t208\t262\t257\t47\t95\t281\t26\t32\t152\t61\t217\t36\t27\t122\t106\t0\t233\t72\t192\t134\t46\t184\t117\t93\t164\t284\n",
      "69\t88\t84\t88\t28\t182\t45\t57\t52\t200\t156\t76\t219\t241\t107\t188\t34\t245\t236\t121\t151\t233\t0\t175\t57\t115\t213\t77\t144\t170\t97\t79\n",
      "216\t107\t119\t235\t175\t21\t150\t204\t199\t39\t37\t223\t58\t80\t94\t27\t159\t84\t75\t64\t48\t72\t175\t0\t134\t76\t52\t126\t59\t35\t106\t226\n",
      "98\t47\t43\t117\t57\t141\t32\t86\t81\t159\t115\t105\t178\t200\t66\t147\t41\t204\t195\t80\t110\t192\t57\t134\t0\t74\t172\t36\t103\t129\t56\t108\n",
      "156\t47\t59\t175\t115\t83\t90\t144\t139\t101\t57\t163\t120\t142\t34\t89\t99\t146\t137\t22\t52\t134\t115\t76\t74\t0\t114\t66\t45\t71\t46\t166\n",
      "254\t145\t157\t273\t213\t45\t188\t242\t237\t27\t75\t261\t32\t54\t132\t41\t197\t58\t49\t102\t86\t46\t213\t52\t172\t114\t0\t164\t97\t73\t144\t264\n",
      "118\t39\t35\t137\t77\t133\t52\t106\t101\t151\t107\t125\t170\t192\t58\t139\t61\t196\t187\t72\t102\t184\t77\t126\t36\t66\t164\t0\t95\t121\t48\t128\n",
      "185\t76\t88\t204\t144\t66\t119\t173\t168\t84\t40\t192\t103\t125\t63\t72\t128\t129\t120\t33\t35\t117\t144\t59\t103\t45\t97\t95\t0\t54\t75\t195\n",
      "211\t102\t114\t230\t170\t42\t145\t199\t194\t60\t32\t218\t79\t101\t89\t48\t154\t105\t96\t59\t43\t93\t170\t35\t129\t71\t73\t121\t54\t0\t101\t221\n",
      "138\t29\t41\t157\t97\t113\t72\t126\t121\t131\t87\t145\t150\t172\t38\t119\t81\t176\t167\t52\t82\t164\t97\t106\t56\t46\t144\t48\t75\t101\t0\t148\n",
      "34\t139\t135\t19\t61\t233\t96\t46\t55\t251\t207\t21\t270\t292\t158\t239\t85\t296\t287\t172\t202\t284\t79\t226\t108\t166\t264\t128\t195\t221\t148\t0\n"
     ]
    }
   ],
   "source": [
    "def build_graph(edges):\n",
    "    # Create adjacency list representation with weights\n",
    "    graph = {}\n",
    "    for edge in edges:\n",
    "        source, dest_weight = edge.split('->')\n",
    "        dest, weight = dest_weight.split(':')\n",
    "        source, dest, weight = int(source), int(dest), int(weight)\n",
    "        \n",
    "        # Initialize dict entries if they don't exist\n",
    "        if source not in graph:\n",
    "            graph[source] = {}\n",
    "        if dest not in graph:\n",
    "            graph[dest] = {}\n",
    "            \n",
    "        # Add edges (undirected graph)\n",
    "        graph[source][dest] = weight\n",
    "        graph[dest][source] = weight\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def find_path_length(graph, start, end, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    \n",
    "    # If we reached the destination\n",
    "    if start == end:\n",
    "        return 0\n",
    "    \n",
    "    visited.add(start)\n",
    "    min_length = float('inf')\n",
    "    \n",
    "    # Try all possible next nodes\n",
    "    for next_node in graph[start]:\n",
    "        if next_node not in visited:\n",
    "            length = find_path_length(graph, next_node, end, visited)\n",
    "            if length != float('inf'):\n",
    "                min_length = min(min_length, length + graph[start][next_node])\n",
    "                \n",
    "    visited.remove(start)\n",
    "    return min_length\n",
    "\n",
    "def compute_distances(n, edges):\n",
    "    # Build the graph\n",
    "    graph = build_graph(edges)\n",
    "    \n",
    "    # Initialize distance matrix\n",
    "    distances = [[0] * n for _ in range(n)]\n",
    "    \n",
    "    # Compute distances between all pairs of leaves\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):  # Only compute upper triangle\n",
    "            dist = find_path_length(graph, i, j)\n",
    "            distances[i][j] = dist\n",
    "            distances[j][i] = dist  # Matrix is symmetric\n",
    "    \n",
    "    return distances\n",
    "\n",
    "def main():\n",
    "    # Read input from file\n",
    "    with open('data/dataset_39959_12.txt', 'r') as file:\n",
    "        # Read number of leaves\n",
    "        n = int(file.readline().strip())\n",
    "        \n",
    "        # Read edges\n",
    "        edges = []\n",
    "        for line in file:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                edges.append(line.strip())\n",
    "    \n",
    "    # Compute distances\n",
    "    distances = compute_distances(n, edges)\n",
    "    \n",
    "    # Print output\n",
    "    for row in distances:\n",
    "        print('\\t'.join(map(str, row)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521\n"
     ]
    }
   ],
   "source": [
    "def limb_length(n, j, D):\n",
    "    # Initialize minimum length as infinity\n",
    "    min_length = float('inf')\n",
    "    \n",
    "    # Try all pairs of leaves i and k where i ≠ j and k ≠ j\n",
    "    for i in range(n):\n",
    "        if i == j:\n",
    "            continue\n",
    "        for k in range(i + 1, n):  # k > i to avoid counting pairs twice\n",
    "            if k == j:\n",
    "                continue\n",
    "            \n",
    "            # Calculate (Di,j + Dj,k - Di,k)/2\n",
    "            length = (D[i][j] + D[j][k] - D[i][k]) / 2\n",
    "            min_length = min(min_length, length)\n",
    "    \n",
    "    return int(min_length)  # Convert to integer as per problem requirements\n",
    "\n",
    "def main():\n",
    "    # Read input from file\n",
    "    with open('data/dataset_39960_8.txt', 'r') as file:\n",
    "        # Read n\n",
    "        n = int(file.readline().strip())\n",
    "        \n",
    "        # Read j\n",
    "        j = int(file.readline().strip())\n",
    "        \n",
    "        # Read distance matrix\n",
    "        D = []\n",
    "        for _ in range(n):\n",
    "            row = list(map(int, file.readline().strip().split()))\n",
    "            D.append(row)\n",
    "    \n",
    "    # Calculate limb length\n",
    "    result = limb_length(n, j, D)\n",
    "    \n",
    "    # Print result\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aispace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
