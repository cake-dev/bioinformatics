{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import toyplot\n",
    "from collections import defaultdict\n",
    "from typing import List, Set, Tuple, Dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Kmers and their counts from a given sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmer_count_from_sequence(sequence, k=3, cyclic=True):\n",
    "    \"\"\"\n",
    "    Returns dictionary with keys representing all possible kmers in a sequence\n",
    "    and values counting their occurrence in the sequence.\n",
    "    \"\"\"\n",
    "    # dict to store kmers\n",
    "    kmers = {}\n",
    "    \n",
    "    # count how many times each occurred in this sequence (treated as cyclic)\n",
    "    for i in range(0, len(sequence)):\n",
    "        kmer = sequence[i:i + k]\n",
    "        \n",
    "        # for cyclic sequence get kmers that wrap from end to beginning\n",
    "        length = len(kmer)\n",
    "        if cyclic:\n",
    "            if len(kmer) != k:\n",
    "                kmer += sequence[:(k - length)]\n",
    "        \n",
    "        # if not cyclic then skip kmers at end of sequence\n",
    "        else:\n",
    "            if len(kmer) != k:\n",
    "                continue\n",
    "        \n",
    "        # count occurrence of this kmer in sequence\n",
    "        if kmer in kmers:\n",
    "            kmers[kmer] += 1\n",
    "        else:\n",
    "            kmers[kmer] = 1\n",
    "    \n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the De Bruijn graph from the Kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_debruijn_edges_from_kmers(kmers):\n",
    "#     \"\"\"\n",
    "#     Every possible (k-1)mer (n-1 suffix and prefix of kmers) is assigned\n",
    "#     to a node, and we connect one node to another if the (k-1)mer overlaps \n",
    "#     another. Nodes are (k-1)mers, edges are kmers.\n",
    "#     \"\"\"\n",
    "#     # store edges as tuples in a set\n",
    "#     edges = set()\n",
    "    \n",
    "#     # compare each (k-1)mer\n",
    "#     for k1 in kmers:\n",
    "#         for k2 in kmers:\n",
    "#             if k1 != k2:            \n",
    "#                 # if they overlap then add to edges\n",
    "#                 if k1[1:] == k2[:-1]:\n",
    "#                     edges.add((k1[:-1], k2[:-1]))\n",
    "#                 if k1[:-1] == k2[1:]:\n",
    "#                     edges.add((k2[:-1], k1[:-1]))\n",
    "\n",
    "#     return edges\n",
    "def get_debruijn_edges_from_kmers(kmers):\n",
    "    \"\"\"\n",
    "    Modified to return both edges and the original kmers that created them.\n",
    "    Every kmer creates one edge connecting its (k-1) prefix to its (k-1) suffix.\n",
    "    \"\"\"\n",
    "    # store edges as tuples with the full kmer that created them\n",
    "    edges = []\n",
    "    \n",
    "    # create edge for each kmer\n",
    "    for kmer in kmers:\n",
    "        # connect prefix to suffix, store original kmer\n",
    "        edges.append((kmer[:-1], kmer[1:], kmer))\n",
    "        \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the De Bruijn graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_debruijn_graph(edges, width=500, height=500):\n",
    "    \"returns a toyplot graph from an input of edges\"\n",
    "    graph = toyplot.graph(\n",
    "        [i[0] for i in edges],\n",
    "        [i[1] for i in edges],\n",
    "        width=width,\n",
    "        height=height,\n",
    "        tmarker=\">\", \n",
    "        vsize=25,\n",
    "        vstyle={\"stroke\": \"black\", \"stroke-width\": 2, \"fill\": \"white\"},\n",
    "        vlstyle={\"font-size\": \"11px\"},\n",
    "        estyle={\"stroke\": \"black\", \"stroke-width\": 2},\n",
    "        layout=toyplot.layout.FruchtermanReingold(edges=toyplot.layout.CurvedEdges()))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate a random sequence of DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sequence(seqlen):\n",
    "    \"Generate a random DNA sequence of a given length \"\n",
    "    return \"\".join([random.choice(\"ACGT\") for i in range(seqlen)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find all possible reconstructions of a sequence from its Kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_reconstructions(edges: List[Tuple[str, str, str]], k: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Finds all possible sequence reconstructions from a de Bruijn graph using all possible Euler paths.\n",
    "    \n",
    "    Args:\n",
    "        edges: List of tuples representing edges in the de Bruijn graph\n",
    "            Each edge is a tuple of (prefix, suffix, original_kmer)\n",
    "        k: Length of original kmers\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: List of all possible reconstructed sequences\n",
    "    \"\"\"\n",
    "    def build_graph(edges: List[Tuple[str, str, str]]) -> Dict[str, List[Tuple[str, str]]]:\n",
    "        \"\"\"Creates adjacency list representation of the graph, preserving original kmers.\"\"\"\n",
    "        graph = defaultdict(list)\n",
    "        for prefix, suffix, kmer in edges:\n",
    "            graph[prefix].append((suffix, kmer))\n",
    "        return graph\n",
    "    \n",
    "    def calculate_degrees(edges: List[Tuple[str, str, str]]) -> Tuple[Dict[str, int], Dict[str, int]]:\n",
    "        \"\"\"Calculates in-degree and out-degree for all nodes.\"\"\"\n",
    "        in_degree = defaultdict(int)\n",
    "        out_degree = defaultdict(int)\n",
    "        for prefix, suffix, _ in edges:\n",
    "            out_degree[prefix] += 1\n",
    "            in_degree[suffix] += 1\n",
    "        return in_degree, out_degree\n",
    "    \n",
    "    def find_start_nodes(graph: Dict[str, List[Tuple[str, str]]], \n",
    "                        edges: List[Tuple[str, str, str]]) -> List[str]:\n",
    "        \"\"\"Finds all possible valid start nodes for Euler paths.\"\"\"\n",
    "        # For cyclic sequences, any node can be a start\n",
    "        return list(set(prefix for prefix, _, _ in edges))\n",
    "    \n",
    "    def find_euler_paths(graph: Dict[str, List[Tuple[str, str]]], start: str, \n",
    "                        target_length: int, path: List[str] = None,\n",
    "                        kmers_used: List[str] = None) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Recursively finds all possible Euler paths starting from given node.\n",
    "        Tracks original kmers used to ensure correct sequence length.\n",
    "        \"\"\"\n",
    "        if path is None:\n",
    "            path = [start]\n",
    "            kmers_used = []\n",
    "            \n",
    "        # Check if we've reached target length\n",
    "        if len(kmers_used) == target_length:\n",
    "            return [kmers_used]\n",
    "            \n",
    "        current = path[-1]\n",
    "        if not graph[current]:\n",
    "            return []\n",
    "            \n",
    "        # Try all possible next nodes\n",
    "        all_paths = []\n",
    "        neighbors = graph[current].copy()  # Copy to avoid modifying during iteration\n",
    "        \n",
    "        for next_node, kmer in neighbors:\n",
    "            # Remove this edge\n",
    "            graph[current].remove((next_node, kmer))\n",
    "            \n",
    "            # Recursively find all paths from next node\n",
    "            new_paths = find_euler_paths(graph, next_node, target_length,\n",
    "                                       path + [next_node],\n",
    "                                       kmers_used + [kmer])\n",
    "            all_paths.extend(new_paths)\n",
    "            \n",
    "            # Restore the edge for backtracking\n",
    "            graph[current].append((next_node, kmer))\n",
    "            \n",
    "        return all_paths\n",
    "    \n",
    "    def reconstruct_from_kmers(kmers: List[str]) -> str:\n",
    "        \"\"\"Reconstructs sequence from ordered list of kmers.\"\"\"\n",
    "        if not kmers:\n",
    "            return \"\"\n",
    "        sequence = kmers[0]\n",
    "        for i in range(1, len(kmers)):\n",
    "            sequence += kmers[i][-1]\n",
    "        return sequence\n",
    "\n",
    "    # Main reconstruction logic\n",
    "    graph = build_graph(edges)\n",
    "    start_nodes = find_start_nodes(graph, edges)\n",
    "    \n",
    "    # Calculate target length based on number of kmers needed\n",
    "    # For cyclic sequence with k-length kmers, need len(sequence) kmers\n",
    "    target_length = len(set(kmer for _, _, kmer in edges))\n",
    "    \n",
    "    # Find all possible reconstructions from all possible start nodes\n",
    "    all_reconstructions = set()\n",
    "    for start_node in start_nodes:\n",
    "        # Create a copy of the graph for each start node\n",
    "        graph_copy = {k: v.copy() for k, v in graph.items()}\n",
    "        kmer_paths = find_euler_paths(graph_copy, start_node, target_length)\n",
    "        \n",
    "        # Convert kmer paths to sequences\n",
    "        for kmer_path in kmer_paths:\n",
    "            sequence = reconstruct_from_kmers(kmer_path)\n",
    "            if len(sequence) == target_length + k - 1:  # Ensure correct length\n",
    "                all_reconstructions.add(sequence)\n",
    "    \n",
    "    return sorted(list(all_reconstructions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verify and score the reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_reconstructions(original: str, reconstructions: List[str], k: int) -> List[bool]:\n",
    "    \"\"\"\n",
    "    Verifies if each reconstructed sequence has the same k-mer composition\n",
    "    and length as the original sequence.\n",
    "    \"\"\"\n",
    "    original_kmers = get_kmer_count_from_sequence(original, k=k, cyclic=True)\n",
    "    return [\n",
    "        len(recon) == len(original) and\n",
    "        get_kmer_count_from_sequence(recon, k=k, cyclic=True) == original_kmers \n",
    "        for recon in reconstructions\n",
    "    ]\n",
    "\n",
    "def score_sequence(original: str, reconstructed: str, \n",
    "                  match_score: float = 1.0, \n",
    "                  mismatch_score: float = -0.5,\n",
    "                  length_penalty: float = -1.0) -> Tuple[float, Dict]:\n",
    "    \"\"\"\n",
    "    Scores a reconstructed sequence against the original, handling unequal lengths.\n",
    "    \n",
    "    Args:\n",
    "        original: Original sequence\n",
    "        reconstructed: Reconstructed sequence to score\n",
    "        match_score: Score for matching bases (default: 1.0)\n",
    "        mismatch_score: Score for mismatching bases (default: -0.5)\n",
    "        length_penalty: Points deducted per base of length difference (default: -1.0)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[float, Dict]: (score, details)\n",
    "            score: Final score including length penalty\n",
    "            details: Dictionary with scoring details\n",
    "    \"\"\"\n",
    "    # Get length of sequence to compare\n",
    "    min_length = min(len(original), len(reconstructed))\n",
    "    length_diff = abs(len(original) - len(reconstructed))\n",
    "    \n",
    "    # Score the overlapping portion\n",
    "    matches = sum(1 for i in range(min_length) if original[i] == reconstructed[i])\n",
    "    mismatches = min_length - matches\n",
    "    \n",
    "    # Calculate base score\n",
    "    base_score = (matches * match_score) + (mismatches * mismatch_score)\n",
    "    \n",
    "    # Apply length penalty\n",
    "    length_penalty_score = length_diff * length_penalty\n",
    "    total_score = base_score + length_penalty_score\n",
    "    \n",
    "    details = {\n",
    "        'matches': matches,\n",
    "        'mismatches': mismatches,\n",
    "        'length_diff': length_diff,\n",
    "        'base_score': base_score,\n",
    "        'length_penalty': length_penalty_score,\n",
    "        'compared_length': min_length,\n",
    "        'percent_identity': (matches / min_length * 100) if min_length > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return total_score, details\n",
    "\n",
    "def score_sequence_with_rotations(original: str, reconstructed: str,\n",
    "                                match_score: float = 1.0,\n",
    "                                mismatch_score: float = -0.5,\n",
    "                                length_penalty: float = -1.0) -> Tuple[float, int, str, Dict]:\n",
    "    \"\"\"\n",
    "    Scores a reconstructed sequence against all possible rotations of the original.\n",
    "    \n",
    "    Args:\n",
    "        original: Original sequence\n",
    "        reconstructed: Reconstructed sequence to score\n",
    "        match_score: Score for matching bases (default: 1.0)\n",
    "        mismatch_score: Score for mismatching bases (default: -0.5)\n",
    "        length_penalty: Points deducted per base of length difference (default: -1.0)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[float, int, str, Dict]: (best_score, best_rotation, best_alignment, best_details)\n",
    "    \"\"\"\n",
    "    # Try all possible rotations\n",
    "    n = len(reconstructed)\n",
    "    best_score = float('-inf')\n",
    "    best_rotation = 0\n",
    "    best_alignment = reconstructed\n",
    "    best_details = {}\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Rotate sequence\n",
    "        rotated = reconstructed[i:] + reconstructed[:i]\n",
    "        # Score this rotation\n",
    "        score, details = score_sequence(original, rotated, \n",
    "                                      match_score, mismatch_score, length_penalty)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_rotation = i\n",
    "            best_alignment = rotated\n",
    "            best_details = details\n",
    "            \n",
    "    return best_score, best_rotation, best_alignment, best_details\n",
    "\n",
    "def evaluate_reconstructions(original: str, reconstructions: List[str],\n",
    "                           match_score: float = 1.0,\n",
    "                           mismatch_score: float = -0.5,\n",
    "                           length_penalty: float = -1.0) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Evaluates all reconstructions against the original sequence.\n",
    "    \n",
    "    Args:\n",
    "        original: Original sequence\n",
    "        reconstructions: List of reconstructed sequences\n",
    "        match_score: Score for matching bases (default: 1.0)\n",
    "        mismatch_score: Score for mismatching bases (default: -0.5)\n",
    "        length_penalty: Points deducted per base of length difference (default: -1.0)\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict]: List of evaluation results for each reconstruction\n",
    "    \"\"\"\n",
    "    evaluations = []\n",
    "    \n",
    "    for recon in reconstructions:\n",
    "        # Get best score and alignment\n",
    "        score, rotation, aligned, details = score_sequence_with_rotations(\n",
    "            original, recon, match_score, mismatch_score, length_penalty)\n",
    "        \n",
    "        evaluation = {\n",
    "            'sequence': recon,\n",
    "            'score': score,\n",
    "            'rotation': rotation,\n",
    "            'aligned': aligned,\n",
    "            'length': len(recon),\n",
    "            'length_diff': details['length_diff'],\n",
    "            'matches': details['matches'],\n",
    "            'mismatches': details['mismatches'],\n",
    "            'base_score': details['base_score'],\n",
    "            'length_penalty': details['length_penalty'],\n",
    "            'percent_identity': details['percent_identity']\n",
    "        }\n",
    "        \n",
    "        evaluations.append(evaluation)\n",
    "    \n",
    "    # Sort evaluations by score, descending\n",
    "    evaluations.sort(key=lambda x: x['score'], reverse=True)\n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Generate random genome\n",
    "genome = random_sequence(50)\n",
    "print(\"Original sequence:\", genome)\n",
    "print(\"Length:\", len(genome))\n",
    "\n",
    "# Get k-mers and build de Bruijn graph\n",
    "k = 50\n",
    "kmers = get_kmer_count_from_sequence(genome, k=k, cyclic=True)\n",
    "edges = get_debruijn_edges_from_kmers(kmers)\n",
    "\n",
    "# Find all possible reconstructions\n",
    "reconstructions = find_all_reconstructions(edges, k)\n",
    "\n",
    "# Add some reconstructions with different lengths for demonstration\n",
    "reconstructions.extend([\n",
    "    reconstructions[0][:-2],  # Shorter\n",
    "    reconstructions[0] + \"AG\"  # Longer\n",
    "])\n",
    "\n",
    "print(f\"\\nFound {len(reconstructions)} possible reconstructions\")\n",
    "\n",
    "# Evaluate reconstructions with default scoring\n",
    "print(\"\\nEvaluating reconstructions (match=1.0, mismatch=-0.5, length_penalty=-1.0):\")\n",
    "evaluations = evaluate_reconstructions(genome, reconstructions)\n",
    "\n",
    "print(\"\\nResults sorted by score:\")\n",
    "print(\"Score | %ID  | Len∆ | Sequence\")\n",
    "print(\"-\" * 60)\n",
    "for eval in evaluations:\n",
    "    print(f\"{eval['score']:5.1f} | {eval['percent_identity']:4.1f}% | {eval['length_diff']:4d} | {eval['aligned']}\")\n",
    "    \n",
    "# Example with different scoring\n",
    "print(\"\\nAlternative scoring (match=2.0, mismatch=-1.0, length_penalty=-2.0):\")\n",
    "alt_evaluations = evaluate_reconstructions(genome, reconstructions, \n",
    "                                        match_score=2.0, \n",
    "                                        mismatch_score=-1.0,\n",
    "                                        length_penalty=-2.0)\n",
    "\n",
    "print(\"\\nResults with alternative scoring:\")\n",
    "print(\"Score | %ID  | Len∆ | Sequence\")\n",
    "print(\"-\" * 60)\n",
    "for eval in alt_evaluations:\n",
    "    print(f\"{eval['score']:5.1f} | {eval['percent_identity']:4.1f}% | {eval['length_diff']:4d} | {eval['aligned']}\")\n",
    "\n",
    "# Print detailed statistics for best reconstruction\n",
    "best = evaluations[0]\n",
    "print(f\"\\nBest reconstruction details:\")\n",
    "print(f\"Score: {best['score']:.1f}\")\n",
    "print(f\"Base score: {best['base_score']:.1f}\")\n",
    "print(f\"Length penalty: {best['length_penalty']:.1f}\")\n",
    "print(f\"Matches: {best['matches']}\")\n",
    "print(f\"Mismatches: {best['mismatches']}\")\n",
    "print(f\"Length difference: {best['length_diff']}\")\n",
    "print(f\"Percent Identity: {best['percent_identity']:.1f}%\")\n",
    "print(f\"Rotation needed: {best['rotation']} positions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import toyplot\n",
    "\n",
    "def get_kmer_count_from_sequence(sequence, k=3, cyclic=True):\n",
    "    \"\"\"\n",
    "    Returns dictionary with keys representing all possible kmers in a sequence\n",
    "    and values counting their occurrence in the sequence.\n",
    "    \"\"\"\n",
    "    # dict to store kmers\n",
    "    kmers = {}\n",
    "    \n",
    "    # count how many times each occurred in this sequence (treated as cyclic)\n",
    "    for i in range(0, len(sequence)):\n",
    "        kmer = sequence[i:i + k]\n",
    "        \n",
    "        # for cyclic sequence get kmers that wrap from end to beginning\n",
    "        length = len(kmer)\n",
    "        if cyclic:\n",
    "            if len(kmer) != k:\n",
    "                kmer += sequence[:(k - length)]\n",
    "        \n",
    "        # if not cyclic then skip kmers at end of sequence\n",
    "        else:\n",
    "            if len(kmer) != k:\n",
    "                continue\n",
    "        \n",
    "        # count occurrence of this kmer in sequence\n",
    "        if kmer in kmers:\n",
    "            kmers[kmer] += 1\n",
    "        else:\n",
    "            kmers[kmer] = 1\n",
    "    \n",
    "    return kmers\n",
    "\n",
    "def short_read_sequencing(sequence, nreads, readlen):\n",
    "    \"generate short reads from a circular genome\"\n",
    "    \n",
    "    # do not allow reads to be longer than genome\n",
    "    assert len(sequence) > readlen, \"readlen must be shorter than sequence\"\n",
    "    \n",
    "    # get random start positions of short reads\n",
    "    starts = [random.randint(0, len(sequence)) for i in range(nreads)]\n",
    "    \n",
    "    # return reads as a list, generate reads by slicing from sequence\n",
    "    reads = []\n",
    "    for position in starts:\n",
    "        end = position + readlen\n",
    "        \n",
    "        # if read extends past end then loop to beginning of sequence\n",
    "        if end > len(sequence):\n",
    "            read = sequence[position:len(sequence)] + sequence[0:end-len(sequence)]\n",
    "        else:\n",
    "            read = sequence[position:position + readlen]\n",
    "        \n",
    "        # append to reads list\n",
    "        reads.append(read)\n",
    "    return reads\n",
    "\n",
    "def get_kmer_count_from_reads(reads, k=3):\n",
    "    \"Combines results of 'get_kmer_count_from_sequence()' across many reads\"\n",
    "   \n",
    "    # a dictionary to store kmer counts in\n",
    "    kmers = {}\n",
    "    \n",
    "    # iterate over reads\n",
    "    for read in reads:\n",
    "        \n",
    "        # get kmer count for this read\n",
    "        ikmers = get_kmer_count_from_sequence(read, k, cyclic=False)\n",
    "        \n",
    "        # add this kmer count to the global kmer counter across all reads\n",
    "        for key, value in ikmers.items():\n",
    "            if key in kmers:\n",
    "                kmers[key] += value\n",
    "            else:\n",
    "                kmers[key] = value\n",
    "                \n",
    "    # return kmer counts\n",
    "    return kmers\n",
    "\n",
    "# def get_debruijn_edges_from_kmers(kmers):\n",
    "#     \"\"\"\n",
    "#     Every possible (k-1)mer (n-1 suffix and prefix of kmers) is assigned\n",
    "#     to a node, and we connect one node to another if the (k-1)mer overlaps \n",
    "#     another. Nodes are (k-1)mers, edges are kmers.\n",
    "#     \"\"\"\n",
    "#     # store edges as tuples in a set\n",
    "#     edges = set()\n",
    "    \n",
    "#     # compare each (k-1)mer\n",
    "#     for k1 in kmers:\n",
    "#         for k2 in kmers:\n",
    "#             if k1 != k2:            \n",
    "#                 # if they overlap then add to edges\n",
    "#                 if k1[1:] == k2[:-1]:\n",
    "#                     edges.add((k1[:-1], k2[:-1]))\n",
    "#                 if k1[:-1] == k2[1:]:\n",
    "#                     edges.add((k2[:-1], k1[:-1]))\n",
    "\n",
    "#     return edges\n",
    "def get_debruijn_edges_from_kmers(kmers):\n",
    "    \"\"\"\n",
    "    Modified to return both edges and the original kmers that created them.\n",
    "    Every kmer creates one edge connecting its (k-1) prefix to its (k-1) suffix.\n",
    "    \"\"\"\n",
    "    # store edges as tuples with the full kmer that created them\n",
    "    edges = []\n",
    "    \n",
    "    # create edge for each kmer\n",
    "    for kmer in kmers:\n",
    "        # connect prefix to suffix, store original kmer\n",
    "        edges.append((kmer[:-1], kmer[1:], kmer))\n",
    "        \n",
    "    return edges\n",
    "\n",
    "def plot_debruijn_graph(edges, width=500, height=500):\n",
    "    \"returns a toyplot graph from an input of edges\"\n",
    "    graph = toyplot.graph(\n",
    "        [i[0] for i in edges],\n",
    "        [i[1] for i in edges],\n",
    "        width=width,\n",
    "        height=height,\n",
    "        tmarker=\">\", \n",
    "        vsize=25,\n",
    "        vstyle={\"stroke\": \"black\", \"stroke-width\": 2, \"fill\": \"white\"},\n",
    "        vlstyle={\"font-size\": \"11px\"},\n",
    "        estyle={\"stroke\": \"black\", \"stroke-width\": 2},\n",
    "        layout=toyplot.layout.FruchtermanReingold(edges=toyplot.layout.CurvedEdges()))\n",
    "    return graph\n",
    "\n",
    "def random_sequence(seqlen):\n",
    "    \"Generate a random DNA sequence of a given length \"\n",
    "    return \"\".join([random.choice(\"ACGT\") for i in range(seqlen)])\n",
    "\n",
    "# set a random seed \n",
    "random.seed(123)\n",
    "\n",
    "# get a random genome sequence\n",
    "genome1 = random_sequence(25)\n",
    "genome1\n",
    "\n",
    "# get kmers\n",
    "kmers = get_kmer_count_from_sequence(genome1, k=3, cyclic=True)\n",
    "\n",
    "# get db graph\n",
    "edges = get_debruijn_edges_from_kmers(kmers)\n",
    "\n",
    "# plot db graph\n",
    "plot_debruijn_graph(edges, width=600, height=400);\n",
    "\n",
    "# print the true sequence\n",
    "print(\"the true sequence: {}\".format(genome1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import List, Set, Tuple, Dict\n",
    "import numpy as np\n",
    "\n",
    "def find_all_reconstructions(edges: List[Tuple[str, str, str]], k: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Finds all possible sequence reconstructions from a de Bruijn graph using all possible Euler paths.\n",
    "    \n",
    "    Args:\n",
    "        edges: List of tuples representing edges in the de Bruijn graph\n",
    "            Each edge is a tuple of (prefix, suffix, original_kmer)\n",
    "        k: Length of original kmers\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: List of all possible reconstructed sequences\n",
    "    \"\"\"\n",
    "    def build_graph(edges: List[Tuple[str, str, str]]) -> Dict[str, List[Tuple[str, str]]]:\n",
    "        \"\"\"Creates adjacency list representation of the graph, preserving original kmers.\"\"\"\n",
    "        graph = defaultdict(list)\n",
    "        for prefix, suffix, kmer in edges:\n",
    "            graph[prefix].append((suffix, kmer))\n",
    "        return graph\n",
    "    \n",
    "    def calculate_degrees(edges: List[Tuple[str, str, str]]) -> Tuple[Dict[str, int], Dict[str, int]]:\n",
    "        \"\"\"Calculates in-degree and out-degree for all nodes.\"\"\"\n",
    "        in_degree = defaultdict(int)\n",
    "        out_degree = defaultdict(int)\n",
    "        for prefix, suffix, _ in edges:\n",
    "            out_degree[prefix] += 1\n",
    "            in_degree[suffix] += 1\n",
    "        return in_degree, out_degree\n",
    "    \n",
    "    def find_start_nodes(graph: Dict[str, List[Tuple[str, str]]], \n",
    "                        edges: List[Tuple[str, str, str]]) -> List[str]:\n",
    "        \"\"\"Finds all possible valid start nodes for Euler paths.\"\"\"\n",
    "        # For cyclic sequences, any node can be a start\n",
    "        return list(set(prefix for prefix, _, _ in edges))\n",
    "    \n",
    "    def find_euler_paths(graph: Dict[str, List[Tuple[str, str]]], start: str, \n",
    "                        target_length: int, path: List[str] = None,\n",
    "                        kmers_used: List[str] = None) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Recursively finds all possible Euler paths starting from given node.\n",
    "        Tracks original kmers used to ensure correct sequence length.\n",
    "        \"\"\"\n",
    "        if path is None:\n",
    "            path = [start]\n",
    "            kmers_used = []\n",
    "            \n",
    "        # Check if we've reached target length\n",
    "        if len(kmers_used) == target_length:\n",
    "            return [kmers_used]\n",
    "            \n",
    "        current = path[-1]\n",
    "        if not graph[current]:\n",
    "            return []\n",
    "            \n",
    "        # Try all possible next nodes\n",
    "        all_paths = []\n",
    "        neighbors = graph[current].copy()  # Copy to avoid modifying during iteration\n",
    "        \n",
    "        for next_node, kmer in neighbors:\n",
    "            # Remove this edge\n",
    "            graph[current].remove((next_node, kmer))\n",
    "            \n",
    "            # Recursively find all paths from next node\n",
    "            new_paths = find_euler_paths(graph, next_node, target_length,\n",
    "                                       path + [next_node],\n",
    "                                       kmers_used + [kmer])\n",
    "            all_paths.extend(new_paths)\n",
    "            \n",
    "            # Restore the edge for backtracking\n",
    "            graph[current].append((next_node, kmer))\n",
    "            \n",
    "        return all_paths\n",
    "    \n",
    "    def reconstruct_from_kmers(kmers: List[str]) -> str:\n",
    "        \"\"\"Reconstructs sequence from ordered list of kmers.\"\"\"\n",
    "        if not kmers:\n",
    "            return \"\"\n",
    "        sequence = kmers[0]\n",
    "        for i in range(1, len(kmers)):\n",
    "            sequence += kmers[i][-1]\n",
    "        return sequence\n",
    "\n",
    "    # Main reconstruction logic\n",
    "    graph = build_graph(edges)\n",
    "    start_nodes = find_start_nodes(graph, edges)\n",
    "    \n",
    "    # Calculate target length based on number of kmers needed\n",
    "    # For cyclic sequence with k-length kmers, need len(sequence) kmers\n",
    "    target_length = len(set(kmer for _, _, kmer in edges))\n",
    "    \n",
    "    # Find all possible reconstructions from all possible start nodes\n",
    "    all_reconstructions = set()\n",
    "    for start_node in start_nodes:\n",
    "        # Create a copy of the graph for each start node\n",
    "        graph_copy = {k: v.copy() for k, v in graph.items()}\n",
    "        kmer_paths = find_euler_paths(graph_copy, start_node, target_length)\n",
    "        \n",
    "        # Convert kmer paths to sequences\n",
    "        for kmer_path in kmer_paths:\n",
    "            sequence = reconstruct_from_kmers(kmer_path)\n",
    "            if len(sequence) == target_length + k - 1:  # Ensure correct length\n",
    "                all_reconstructions.add(sequence)\n",
    "    \n",
    "    return sorted(list(all_reconstructions))\n",
    "\n",
    "def verify_reconstructions(original: str, reconstructions: List[str], k: int) -> List[bool]:\n",
    "    \"\"\"\n",
    "    Verifies if each reconstructed sequence has the same k-mer composition\n",
    "    and length as the original sequence.\n",
    "    \"\"\"\n",
    "    original_kmers = get_kmer_count_from_sequence(original, k=k, cyclic=True)\n",
    "    return [\n",
    "        len(recon) == len(original) and\n",
    "        get_kmer_count_from_sequence(recon, k=k, cyclic=True) == original_kmers \n",
    "        for recon in reconstructions\n",
    "    ]\n",
    "\n",
    "def score_sequence(original: str, reconstructed: str, \n",
    "                  match_score: float = 1.0, \n",
    "                  mismatch_score: float = -0.5,\n",
    "                  length_penalty: float = -1.0) -> Tuple[float, Dict]:\n",
    "    \"\"\"\n",
    "    Scores a reconstructed sequence against the original, handling unequal lengths.\n",
    "    \n",
    "    Args:\n",
    "        original: Original sequence\n",
    "        reconstructed: Reconstructed sequence to score\n",
    "        match_score: Score for matching bases (default: 1.0)\n",
    "        mismatch_score: Score for mismatching bases (default: -0.5)\n",
    "        length_penalty: Points deducted per base of length difference (default: -1.0)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[float, Dict]: (score, details)\n",
    "            score: Final score including length penalty\n",
    "            details: Dictionary with scoring details\n",
    "    \"\"\"\n",
    "    # Get length of sequence to compare\n",
    "    min_length = min(len(original), len(reconstructed))\n",
    "    length_diff = abs(len(original) - len(reconstructed))\n",
    "    \n",
    "    # Score the overlapping portion\n",
    "    matches = sum(1 for i in range(min_length) if original[i] == reconstructed[i])\n",
    "    mismatches = min_length - matches\n",
    "    \n",
    "    # Calculate base score\n",
    "    base_score = (matches * match_score) + (mismatches * mismatch_score)\n",
    "    \n",
    "    # Apply length penalty\n",
    "    length_penalty_score = length_diff * length_penalty\n",
    "    total_score = base_score + length_penalty_score\n",
    "    \n",
    "    details = {\n",
    "        'matches': matches,\n",
    "        'mismatches': mismatches,\n",
    "        'length_diff': length_diff,\n",
    "        'base_score': base_score,\n",
    "        'length_penalty': length_penalty_score,\n",
    "        'compared_length': min_length,\n",
    "        'percent_identity': (matches / min_length * 100) if min_length > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return total_score, details\n",
    "\n",
    "def score_sequence_with_rotations(original: str, reconstructed: str,\n",
    "                                match_score: float = 1.0,\n",
    "                                mismatch_score: float = -0.5,\n",
    "                                length_penalty: float = -1.0) -> Tuple[float, int, str, Dict]:\n",
    "    \"\"\"\n",
    "    Scores a reconstructed sequence against all possible rotations of the original.\n",
    "    \n",
    "    Args:\n",
    "        original: Original sequence\n",
    "        reconstructed: Reconstructed sequence to score\n",
    "        match_score: Score for matching bases (default: 1.0)\n",
    "        mismatch_score: Score for mismatching bases (default: -0.5)\n",
    "        length_penalty: Points deducted per base of length difference (default: -1.0)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[float, int, str, Dict]: (best_score, best_rotation, best_alignment, best_details)\n",
    "    \"\"\"\n",
    "    # Try all possible rotations\n",
    "    n = len(reconstructed)\n",
    "    best_score = float('-inf')\n",
    "    best_rotation = 0\n",
    "    best_alignment = reconstructed\n",
    "    best_details = {}\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Rotate sequence\n",
    "        rotated = reconstructed[i:] + reconstructed[:i]\n",
    "        # Score this rotation\n",
    "        score, details = score_sequence(original, rotated, \n",
    "                                      match_score, mismatch_score, length_penalty)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_rotation = i\n",
    "            best_alignment = rotated\n",
    "            best_details = details\n",
    "            \n",
    "    return best_score, best_rotation, best_alignment, best_details\n",
    "\n",
    "def evaluate_reconstructions(original: str, reconstructions: List[str],\n",
    "                           match_score: float = 1.0,\n",
    "                           mismatch_score: float = -0.5,\n",
    "                           length_penalty: float = -1.0) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Evaluates all reconstructions against the original sequence.\n",
    "    \n",
    "    Args:\n",
    "        original: Original sequence\n",
    "        reconstructions: List of reconstructed sequences\n",
    "        match_score: Score for matching bases (default: 1.0)\n",
    "        mismatch_score: Score for mismatching bases (default: -0.5)\n",
    "        length_penalty: Points deducted per base of length difference (default: -1.0)\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict]: List of evaluation results for each reconstruction\n",
    "    \"\"\"\n",
    "    evaluations = []\n",
    "    \n",
    "    for recon in reconstructions:\n",
    "        # Get best score and alignment\n",
    "        score, rotation, aligned, details = score_sequence_with_rotations(\n",
    "            original, recon, match_score, mismatch_score, length_penalty)\n",
    "        \n",
    "        evaluation = {\n",
    "            'sequence': recon,\n",
    "            'score': score,\n",
    "            'rotation': rotation,\n",
    "            'aligned': aligned,\n",
    "            'length': len(recon),\n",
    "            'length_diff': details['length_diff'],\n",
    "            'matches': details['matches'],\n",
    "            'mismatches': details['mismatches'],\n",
    "            'base_score': details['base_score'],\n",
    "            'length_penalty': details['length_penalty'],\n",
    "            'percent_identity': details['percent_identity']\n",
    "        }\n",
    "        \n",
    "        evaluations.append(evaluation)\n",
    "    \n",
    "    # Sort evaluations by score, descending\n",
    "    evaluations.sort(key=lambda x: x['score'], reverse=True)\n",
    "    return evaluations\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(42)\n",
    "    \n",
    "    # Generate random genome\n",
    "    genome = random_sequence(50)\n",
    "    print(\"Original sequence:\", genome)\n",
    "    print(\"Length:\", len(genome))\n",
    "    \n",
    "    # Get k-mers and build de Bruijn graph\n",
    "    k = 50\n",
    "    kmers = get_kmer_count_from_sequence(genome, k=k, cyclic=True)\n",
    "    edges = get_debruijn_edges_from_kmers(kmers)\n",
    "    \n",
    "    # Find all possible reconstructions\n",
    "    reconstructions = find_all_reconstructions(edges, k)\n",
    "    \n",
    "    # Add some reconstructions with different lengths for demonstration\n",
    "    reconstructions.extend([\n",
    "        reconstructions[0][:-2],  # Shorter\n",
    "        reconstructions[0] + \"AG\"  # Longer\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nFound {len(reconstructions)} possible reconstructions\")\n",
    "    \n",
    "    # Evaluate reconstructions with default scoring\n",
    "    print(\"\\nEvaluating reconstructions (match=1.0, mismatch=-0.5, length_penalty=-1.0):\")\n",
    "    evaluations = evaluate_reconstructions(genome, reconstructions)\n",
    "    \n",
    "    print(\"\\nResults sorted by score:\")\n",
    "    print(\"Score | %ID  | Len∆ | Sequence\")\n",
    "    print(\"-\" * 60)\n",
    "    for eval in evaluations:\n",
    "        print(f\"{eval['score']:5.1f} | {eval['percent_identity']:4.1f}% | {eval['length_diff']:4d} | {eval['aligned']}\")\n",
    "        \n",
    "    # Example with different scoring\n",
    "    print(\"\\nAlternative scoring (match=2.0, mismatch=-1.0, length_penalty=-2.0):\")\n",
    "    alt_evaluations = evaluate_reconstructions(genome, reconstructions, \n",
    "                                            match_score=2.0, \n",
    "                                            mismatch_score=-1.0,\n",
    "                                            length_penalty=-2.0)\n",
    "    \n",
    "    print(\"\\nResults with alternative scoring:\")\n",
    "    print(\"Score | %ID  | Len∆ | Sequence\")\n",
    "    print(\"-\" * 60)\n",
    "    for eval in alt_evaluations:\n",
    "        print(f\"{eval['score']:5.1f} | {eval['percent_identity']:4.1f}% | {eval['length_diff']:4d} | {eval['aligned']}\")\n",
    "    \n",
    "    # Print detailed statistics for best reconstruction\n",
    "    best = evaluations[0]\n",
    "    print(f\"\\nBest reconstruction details:\")\n",
    "    print(f\"Score: {best['score']:.1f}\")\n",
    "    print(f\"Base score: {best['base_score']:.1f}\")\n",
    "    print(f\"Length penalty: {best['length_penalty']:.1f}\")\n",
    "    print(f\"Matches: {best['matches']}\")\n",
    "    print(f\"Mismatches: {best['mismatches']}\")\n",
    "    print(f\"Length difference: {best['length_diff']}\")\n",
    "    print(f\"Percent Identity: {best['percent_identity']:.1f}%\")\n",
    "    print(f\"Rotation needed: {best['rotation']} positions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aispace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
